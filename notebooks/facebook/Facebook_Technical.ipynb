{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for Facebook Technical Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are my notes for preparing for the technical portion of the interview. To simulate interview conditions, I wrote all code in markdown mode only converting the cells to executable after I felt comfortable they were correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pandas-dates'></a> [**Pandas - Time Series / Date Functionality**](http://pandas.pydata.org/pandas-docs/version/0.23/timeseries.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uses the numpy ```datetime64``` and ```timedelta64``` datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" class=\"docutils\">\n",
    "<colgroup>\n",
    "<col width=\"15%\">\n",
    "<col width=\"27%\">\n",
    "<col width=\"58%\">\n",
    "</colgroup>\n",
    "\n",
    "<thead valign=\"bottom\">\n",
    "<tr class=\"row-odd\"><th class=\"head\">Class</th>\n",
    "<th class=\"head\">Remarks</th>\n",
    "<th class=\"head\">How to create</th>\n",
    "</tr>\n",
    "</thead><tbody valign=\"top\">\n",
    "<tr class=\"row-even\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">Timestamp</span></code></td>\n",
    "<td>Represents a single timestamp</td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">to_datetime</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">Timestamp</span></code></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></td>\n",
    "<td>Index of <code class=\"docutils literal notranslate\"><span class=\"pre\">Timestamp</span></code></td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">to_datetime</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">date_range</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">bdate_range</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">Period</span></code></td>\n",
    "<td>Represents a single time span</td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">Period</span></code></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">PeriodIndex</span></code></td>\n",
    "<td>Index of <code class=\"docutils literal notranslate\"><span class=\"pre\">Period</span></code></td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">period_range</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">PeriodIndex</span></code></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Both ```Timestamp``` and  ```Period``` objects can serve as an index. They are automatically cast into ```DatetimeIndex``` and ```PeriodIndex``` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casey/coding_interview/interview_venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   2009-07-31\n",
       "1   2010-01-10\n",
       "2          NaT\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Can convert from strings to date-like objects via pd.to_datetime\n",
    "pd.to_datetime(pd.Series(['Jul 31, 2009', '2010-01-10', None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2010-02-20', '2010-02-21', '2010-02-22', '2010-02-23',\n",
       "               '2010-02-24', '2010-02-25', '2010-02-26', '2010-02-27',\n",
       "               '2010-02-28', '2010-03-01',\n",
       "               ...\n",
       "               '2011-02-24', '2011-02-25', '2011-02-26', '2011-02-27',\n",
       "               '2011-02-28', '2011-03-01', '2011-03-02', '2011-03-03',\n",
       "               '2011-03-04', '2011-03-05'],\n",
       "              dtype='datetime64[ns]', length=379, freq='D')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make range of dates:\n",
    "pd.date_range('2010-02-20', '2011-03-05')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pandas-join'></a> [**Pandas - Merge, Join, Concatenate**](https://pandas.pydata.org/pandas-docs/stable/merging.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example dataframes and series\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                   index=[0, 1, 2, 3])\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                    'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                    'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                    'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                   index=[4, 5, 6, 7])\n",
    " \n",
    "\n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                    'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                    'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "                    'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "                   index=[8, 9, 10, 11])\n",
    "s1 = pd.Series(['X0', 'X1', 'X2', 'X3'], name='X')\n",
    "\n",
    "s2 = pd.Series(['X0', 'X1', 'X2', 'X3'],\n",
    "               index=['A', 'B', 'C', 'D'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3\n",
      "\n",
      "A    X0\n",
      "B    X1\n",
      "C    X2\n",
      "D    X3\n",
      "dtype: object\n",
      "\n",
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3\n",
      "4  X0  X1  X2  X3 \n"
     ]
    }
   ],
   "source": [
    "# Note that Series objects are more accurately thought of as row objects rather\n",
    "# than column objects as they are typically displayed\n",
    "\n",
    "result = df1.append(s2, ignore_index=True)\n",
    "print('{}\\n\\n{}\\n\\n{} '.format(df1, s2, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "0    A0   B0   C0   D0\n",
      "1    A1   B1   C1   D1\n",
      "2    A2   B2   C2   D2\n",
      "3    A3   B3   C3   D3\n",
      "4    A4   B4   C4   D4\n",
      "5    A5   B5   C5   D5\n",
      "6    A6   B6   C6   D6\n",
      "7    A7   B7   C7   D7\n",
      "8    A8   B8   C8   D8\n",
      "9    A9   B9   C9   D9\n",
      "10  A10  B10  C10  D10\n",
      "11  A11  B11  C11  D11\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes\n",
    "#\n",
    "# - Argument must be a list of DataFrames or Series, or a dict\n",
    "# - In this example all dataframes have the same columns and non-overlapping\n",
    "################################################################################\n",
    "result = pd.concat([df1, df2, df3])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        A    B    C    D\n",
      "x 0    A0   B0   C0   D0\n",
      "  1    A1   B1   C1   D1\n",
      "  2    A2   B2   C2   D2\n",
      "  3    A3   B3   C3   D3\n",
      "y 4    A4   B4   C4   D4\n",
      "  5    A5   B5   C5   D5\n",
      "  6    A6   B6   C6   D6\n",
      "  7    A7   B7   C7   D7\n",
      "z 8    A8   B8   C8   D8\n",
      "  9    A9   B9   C9   D9\n",
      "  10  A10  B10  C10  D10\n",
      "  11  A11  B11  C11  D11\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes\n",
    "#\n",
    "# - Can attach a distinguishing label for each constituent dataframe now we \n",
    "#     will have a multiindex\n",
    "# - Concat makes a full copy of the data\n",
    "################################################################################\n",
    "result = pd.concat([df1, df2, df3], keys=['x', 'y', 'z'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A   B    C   D    F\n",
      "0   A0  B0   C0  D0  NaN\n",
      "1   A1  B1   C1  D1  NaN\n",
      "2   A2  B2   C2  D2  NaN\n",
      "3   A3  B3   C3  D3  NaN\n",
      "2  NaN  B2  NaN  D2   F2\n",
      "3  NaN  B3  NaN  D3   F3\n",
      "6  NaN  B6  NaN  D6   F6\n",
      "7  NaN  B7  NaN  D7   F7\n",
      "\n",
      "\n",
      "     A    B    C    D    B    D    F\n",
      "0   A0   B0   C0   D0  NaN  NaN  NaN\n",
      "1   A1   B1   C1   D1  NaN  NaN  NaN\n",
      "2   A2   B2   C2   D2   B2   D2   F2\n",
      "3   A3   B3   C3   D3   B3   D3   F3\n",
      "6  NaN  NaN  NaN  NaN   B6   D6   F6\n",
      "7  NaN  NaN  NaN  NaN   B7   D7   F7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casey/coding_interview/interview_venv/lib/python3.5/site-packages/ipykernel_launcher.py:13: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes\n",
    "#\n",
    "# - The default merge method is 'outer' meaning that it will use the union of \n",
    "#     all keys in both dataframes\n",
    "# - Note that with an outer join it fills all missing fields with nans\n",
    "################################################################################\n",
    "df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "                    'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "                    'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "                   index=[2, 3, 6, 7])\n",
    "# Concatenate along rows (i.e. vertical stacking)\n",
    "result = pd.concat([df1, df4], axis=0)\n",
    "print(result)\n",
    "print('\\n')\n",
    "# Concatenate along columns (i.e. horizontal stacking)\n",
    "result = pd.concat([df1, df4], axis=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    B   D\n",
      "0  B0  D0\n",
      "1  B1  D1\n",
      "2  B2  D2\n",
      "3  B3  D3\n",
      "2  B2  D2\n",
      "3  B3  D3\n",
      "6  B6  D6\n",
      "7  B7  D7\n",
      "\n",
      "\n",
      "    A   B   C   D   B   D   F\n",
      "2  A2  B2  C2  D2  B2  D2  F2\n",
      "3  A3  B3  C3  D3  B3  D3  F3\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes\n",
    "#\n",
    "# - A join of inner only returns the columns and rows that can be filled in\n",
    "#     completely, i.e. the intersection\n",
    "################################################################################\n",
    "df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "                    'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "                    'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "                   index=[2, 3, 6, 7])\n",
    "# Concatenate along rows (i.e. vertical stacking)\n",
    "# Drops columns A, C since the are not present in df4, it drops F not in df1\n",
    "result = pd.concat([df1, df4], join='inner', axis=0)\n",
    "print(result)\n",
    "print('\\n')\n",
    "# Concatenate along columns (i.e. horizontal stacking)\n",
    "\n",
    "result = pd.concat([df1, df4], join='inner', axis=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Difference between '```append```, ```concat```, ```merge```, and ```join```**\n",
    "\n",
    "**```append```**\n",
    "* Solely for appending rows to a dataframe, but it is typically slow and seldomly used in favor of concat.\n",
    "* Exists as a dataframe method (i.e. is called via df.append )\n",
    "\n",
    "**```concat```**\n",
    "* For stacking dataframes vertically or horizontally.\n",
    "* Exists in the pandas namespace (i.e. is called via pd.concat)\n",
    "\n",
    "**```merge```**\n",
    "* For performing relational database style stitching\n",
    "\n",
    "**```join```**\n",
    "* A shortcut for merging on indices as opposed to merge which allows you to join along arbitrary columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mock Question from E-mail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An attendance log for every student in a school district ```attendance_events```:\n",
    "\n",
    "| date | student_id | attendance |\n",
    "|:----:|:----------:|:----------:|\n",
    "|      |            |            |\n",
    "\n",
    "A summary table with demographics for each student in the district ```all_students```: \n",
    "\n",
    "|student_id | school_id | grade_level | date_of_birth | hometown |\n",
    "|-----------|-----------|-------------|---------------|----------|\n",
    "\n",
    "Using this data, you could answer questions like the following:\n",
    "\n",
    "* What percent of students attend school on their birthday?\n",
    "* Which grade level had the largest drop in attendance between yesterday and today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Functions used to generate mock data simulating the tables given above.\n",
    "\n",
    "n_students = 1000\n",
    "n_days = 10\n",
    "start_date = '2017-09-01'\n",
    "end_date = '2018-06-15'\n",
    "\n",
    "################################################################################\n",
    "# Attendance Table                                                             #\n",
    "################################################################################\n",
    "def _make_event_dates(n_students, start_date, end_date):\n",
    "    dr = pd.date_range(start_date, end_date)\n",
    "    dates = []\n",
    "    for day in dr:\n",
    "        dates.extend([day] * n_students)\n",
    "    return dates\n",
    "\n",
    "def _make_student_ids(n_students, n_days=None):\n",
    "    student_ids = [xx for xx in range(100, 100 + n_students)]\n",
    "    if n_days is not None:\n",
    "        student_ids = student_ids * n_days\n",
    "    return student_ids\n",
    "\n",
    "def _make_attendance(n_students, n_days):\n",
    "    return list(np.random.choice(2, n_students, p=[0.3, 0.7])) * n_days\n",
    "\n",
    "def build_attendance_events(n_students, start_date, end_date):\n",
    "    columns = ['date', 'student_id', 'attendance']\n",
    "    n_days = len(pd.date_range(start_date, end_date))\n",
    "    \n",
    "    dates       = _make_event_dates(n_students, start_date, end_date)\n",
    "    student_ids = _make_student_ids(n_students, n_days)\n",
    "    attendance  = _make_attendance(n_students, n_days)\n",
    "    data = [xx for xx in zip(dates, student_ids, attendance)]\n",
    "    \n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "    return df\n",
    "\n",
    "################################################################################\n",
    "# District All Students Table                                                  #\n",
    "################################################################################\n",
    "def _make_school_ids(n_students):\n",
    "    schools = ['South River High School',\n",
    "               'New Brunswick High School',\n",
    "               'East Brunswick High School',\n",
    "               'Edison High School']\n",
    "    return list(np.random.choice(schools, n_students))\n",
    "\n",
    "def _make_grade_levels(n_students):\n",
    "    grades = ['Freshman', 'Sophomore', 'Junior', 'Senior']\n",
    "    return list(np.random.choice(grades, n_students))\n",
    "    \n",
    "def _make_DOBs(grade_levels):\n",
    "    birth_years = {\n",
    "        'Freshman': 2005,\n",
    "        'Sophomore': 2004,\n",
    "        'Junior': 2003,\n",
    "        'Senior': 2002\n",
    "    }\n",
    "    years = [birth_years[xx] for xx in grade_levels]\n",
    "    months = list(np.random.choice(np.arange(1,13), len(grade_levels)))\n",
    "    days = list(np.random.choice(np.arange(1,29), len(grade_levels)))\n",
    "    DOBs = pd.to_datetime(['{}-{}-{}'.format(*dd) for dd in zip(months, days, years)])\n",
    "    return DOBs\n",
    "\n",
    "def _make_hometowns(school_ids):\n",
    "    hometowns = [school.split('High School')[0].strip() for school in school_ids]\n",
    "    return hometowns\n",
    "    \n",
    "\n",
    "def build_all_students(n_students):\n",
    "    student_ids  = _make_student_ids(n_students)\n",
    "    school_ids   = _make_school_ids(n_students)\n",
    "    grade_levels = _make_grade_levels(n_students)\n",
    "    DOBs         = _make_DOBs(grade_levels)\n",
    "    hometowns    = _make_hometowns(school_ids)\n",
    "    \n",
    "    columns = ['student_id', 'school_id', 'grade_level', 'date_of_birth', 'hometown']\n",
    "    data = [xx for xx in zip(student_ids, school_ids, grade_levels, DOBs, hometowns)]\n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "    return df\n",
    "    \n",
    "\n",
    "attendance_events = build_attendance_events(n_students, start_date, end_date)\n",
    "all_students = build_all_students(n_students=n_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>student_id</th>\n",
       "      <th>attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  student_id  attendance\n",
       "0 2017-09-01         100           1\n",
       "1 2017-09-01         101           1\n",
       "2 2017-09-01         102           1\n",
       "3 2017-09-01         103           0\n",
       "4 2017-09-01         104           0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>school_id</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>hometown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>New Brunswick High School</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>2005-09-12</td>\n",
       "      <td>New Brunswick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>New Brunswick High School</td>\n",
       "      <td>Sophomore</td>\n",
       "      <td>2004-09-23</td>\n",
       "      <td>New Brunswick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>South River High School</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>2005-06-24</td>\n",
       "      <td>South River</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>East Brunswick High School</td>\n",
       "      <td>Senior</td>\n",
       "      <td>2002-09-05</td>\n",
       "      <td>East Brunswick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>South River High School</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>2005-12-14</td>\n",
       "      <td>South River</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_id                   school_id grade_level date_of_birth  \\\n",
       "0         100   New Brunswick High School    Freshman    2005-09-12   \n",
       "1         101   New Brunswick High School   Sophomore    2004-09-23   \n",
       "2         102     South River High School    Freshman    2005-06-24   \n",
       "3         103  East Brunswick High School      Senior    2002-09-05   \n",
       "4         104     South River High School    Freshman    2005-12-14   \n",
       "\n",
       "         hometown  \n",
       "0   New Brunswick  \n",
       "1   New Brunswick  \n",
       "2     South River  \n",
       "3  East Brunswick  \n",
       "4     South River  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_students.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What percent of students attend school on their birthday?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>student_id</th>\n",
       "      <th>attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287970</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287971</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287972</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287973</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287974</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287975</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287976</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1076</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287977</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287978</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287980</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287981</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1081</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287982</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287983</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1083</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287984</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287985</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287986</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287987</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287988</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287989</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287990</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287991</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287992</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287993</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287994</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287995</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287996</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287997</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287998</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287999</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1099</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  student_id  attendance\n",
       "0      2017-09-01         100           1\n",
       "1      2017-09-01         101           1\n",
       "2      2017-09-01         102           1\n",
       "3      2017-09-01         103           0\n",
       "4      2017-09-01         104           0\n",
       "5      2017-09-01         105           0\n",
       "6      2017-09-01         106           0\n",
       "7      2017-09-01         107           1\n",
       "8      2017-09-01         108           1\n",
       "9      2017-09-01         109           1\n",
       "10     2017-09-01         110           1\n",
       "11     2017-09-01         111           0\n",
       "12     2017-09-01         112           0\n",
       "13     2017-09-01         113           1\n",
       "14     2017-09-01         114           0\n",
       "15     2017-09-01         115           0\n",
       "16     2017-09-01         116           1\n",
       "17     2017-09-01         117           1\n",
       "18     2017-09-01         118           0\n",
       "19     2017-09-01         119           1\n",
       "20     2017-09-01         120           0\n",
       "21     2017-09-01         121           0\n",
       "22     2017-09-01         122           0\n",
       "23     2017-09-01         123           1\n",
       "24     2017-09-01         124           0\n",
       "25     2017-09-01         125           1\n",
       "26     2017-09-01         126           1\n",
       "27     2017-09-01         127           1\n",
       "28     2017-09-01         128           1\n",
       "29     2017-09-01         129           1\n",
       "...           ...         ...         ...\n",
       "287970 2018-06-15        1070           0\n",
       "287971 2018-06-15        1071           1\n",
       "287972 2018-06-15        1072           1\n",
       "287973 2018-06-15        1073           0\n",
       "287974 2018-06-15        1074           1\n",
       "287975 2018-06-15        1075           1\n",
       "287976 2018-06-15        1076           1\n",
       "287977 2018-06-15        1077           0\n",
       "287978 2018-06-15        1078           1\n",
       "287979 2018-06-15        1079           1\n",
       "287980 2018-06-15        1080           1\n",
       "287981 2018-06-15        1081           1\n",
       "287982 2018-06-15        1082           0\n",
       "287983 2018-06-15        1083           1\n",
       "287984 2018-06-15        1084           1\n",
       "287985 2018-06-15        1085           1\n",
       "287986 2018-06-15        1086           1\n",
       "287987 2018-06-15        1087           1\n",
       "287988 2018-06-15        1088           1\n",
       "287989 2018-06-15        1089           1\n",
       "287990 2018-06-15        1090           0\n",
       "287991 2018-06-15        1091           1\n",
       "287992 2018-06-15        1092           1\n",
       "287993 2018-06-15        1093           1\n",
       "287994 2018-06-15        1094           1\n",
       "287995 2018-06-15        1095           1\n",
       "287996 2018-06-15        1096           0\n",
       "287997 2018-06-15        1097           1\n",
       "287998 2018-06-15        1098           0\n",
       "287999 2018-06-15        1099           1\n",
       "\n",
       "[288000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevant Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pandas - Dates and Times](#pandas-dates)\n",
    "\n",
    "[Pandas - Merge, Join, Concatenate](#pandas-join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview_prep",
   "language": "python",
   "name": "interview_prep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
