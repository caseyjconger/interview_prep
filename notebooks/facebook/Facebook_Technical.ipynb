{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for Facebook Technical Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are my notes for preparing for the technical portion of the interview. To simulate interview conditions, I wrote all code in markdown mode only converting the cells to executable after I felt comfortable they were correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pandas-dates'></a> [**Pandas - Time Series / Date Functionality**](http://pandas.pydata.org/pandas-docs/version/0.23/timeseries.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uses the numpy ```datetime64``` and ```timedelta64``` datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" class=\"docutils\">\n",
    "<colgroup>\n",
    "<col width=\"15%\">\n",
    "<col width=\"27%\">\n",
    "<col width=\"58%\">\n",
    "</colgroup>\n",
    "\n",
    "<thead valign=\"bottom\">\n",
    "<tr class=\"row-odd\"><th class=\"head\">Class</th>\n",
    "<th class=\"head\">Remarks</th>\n",
    "<th class=\"head\">How to create</th>\n",
    "</tr>\n",
    "</thead><tbody valign=\"top\">\n",
    "<tr class=\"row-even\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">Timestamp</span></code></td>\n",
    "<td>Represents a single timestamp</td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">to_datetime</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">Timestamp</span></code></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></td>\n",
    "<td>Index of <code class=\"docutils literal notranslate\"><span class=\"pre\">Timestamp</span></code></td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">to_datetime</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">date_range</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">bdate_range</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">Period</span></code></td>\n",
    "<td>Represents a single time span</td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">Period</span></code></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">PeriodIndex</span></code></td>\n",
    "<td>Index of <code class=\"docutils literal notranslate\"><span class=\"pre\">Period</span></code></td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">period_range</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">PeriodIndex</span></code></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Both ```Timestamp``` and  ```Period``` objects can serve as an index. They are automatically cast into ```DatetimeIndex``` and ```PeriodIndex``` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casey/coding_interview/interview_venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   2009-07-31\n",
       "1   2010-01-10\n",
       "2          NaT\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Can convert from strings to date-like objects via pd.to_datetime\n",
    "pd.to_datetime(pd.Series(['Jul 31, 2009', '2010-01-10', None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2010-02-20', '2010-02-21', '2010-02-22', '2010-02-23',\n",
       "               '2010-02-24', '2010-02-25', '2010-02-26', '2010-02-27',\n",
       "               '2010-02-28', '2010-03-01',\n",
       "               ...\n",
       "               '2011-02-24', '2011-02-25', '2011-02-26', '2011-02-27',\n",
       "               '2011-02-28', '2011-03-01', '2011-03-02', '2011-03-03',\n",
       "               '2011-03-04', '2011-03-05'],\n",
       "              dtype='datetime64[ns]', length=379, freq='D')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make range of dates:\n",
    "pd.date_range('2010-02-20', '2011-03-05')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pandas-join'></a> [**Pandas - Merge, Join, Concatenate**](https://pandas.pydata.org/pandas-docs/stable/merging.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Difference between '```append```, ```concat```, ```merge```, and ```join```**\n",
    "\n",
    "**```append```**\n",
    "* Solely for appending rows to a dataframe, but it is typically slow and seldomly used in favor of concat.\n",
    "* Exists as a dataframe method (i.e. is called via df.append )\n",
    "\n",
    "**```concat```**\n",
    "* For stacking dataframes vertically or horizontally.\n",
    "* Exists in the pandas namespace (i.e. is called via pd.concat)\n",
    "\n",
    "**```merge```**\n",
    "* For performing relational database style stitching\n",
    "\n",
    "**```join```**\n",
    "* A shortcut for merging on indices as opposed to merge which allows you to join along arbitrary columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" class=\"colwidths-given docutils\">\n",
    "<colgroup>\n",
    "<col width=\"20%\">\n",
    "<col width=\"20%\">\n",
    "<col width=\"60%\">\n",
    "</colgroup>\n",
    "<thead valign=\"bottom\">\n",
    "<tr class=\"row-odd\"><th class=\"head\">Merge method</th>\n",
    "<th class=\"head\">SQL Join Name</th>\n",
    "<th class=\"head\">Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody valign=\"top\">\n",
    "<tr class=\"row-even\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">left</span></code></td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">LEFT</span> <span class=\"pre\">OUTER</span> <span class=\"pre\">JOIN</span></code></td>\n",
    "<td>Use keys from left frame only</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">right</span></code></td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">RIGHT</span> <span class=\"pre\">OUTER</span> <span class=\"pre\">JOIN</span></code></td>\n",
    "<td>Use keys from right frame only</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">outer</span></code></td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">FULL</span> <span class=\"pre\">OUTER</span> <span class=\"pre\">JOIN</span></code></td>\n",
    "<td>Use union of keys from both frames</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">inner</span></code></td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">INNER</span> <span class=\"pre\">JOIN</span></code></td>\n",
    "<td>Use intersection of keys from both frames</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example dataframes and series\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                   index=[0, 1, 2, 3])\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                    'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                    'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                    'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                   index=[4, 5, 6, 7])\n",
    " \n",
    "\n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                    'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                    'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "                    'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "                   index=[8, 9, 10, 11])\n",
    "s1 = pd.Series(['X0', 'X1', 'X2', 'X3'], name='X')\n",
    "\n",
    "s2 = pd.Series(['X0', 'X1', 'X2', 'X3'],\n",
    "               index=['A', 'B', 'C', 'D'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3\n",
      "\n",
      "A    X0\n",
      "B    X1\n",
      "C    X2\n",
      "D    X3\n",
      "dtype: object\n",
      "\n",
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3\n",
      "4  X0  X1  X2  X3 \n"
     ]
    }
   ],
   "source": [
    "# Note that Series objects are more accurately thought of as row objects rather\n",
    "# than column objects as they are typically displayed\n",
    "\n",
    "result = df1.append(s2, ignore_index=True)\n",
    "print('{}\\n\\n{}\\n\\n{} '.format(df1, s2, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "0    A0   B0   C0   D0\n",
      "1    A1   B1   C1   D1\n",
      "2    A2   B2   C2   D2\n",
      "3    A3   B3   C3   D3\n",
      "4    A4   B4   C4   D4\n",
      "5    A5   B5   C5   D5\n",
      "6    A6   B6   C6   D6\n",
      "7    A7   B7   C7   D7\n",
      "8    A8   B8   C8   D8\n",
      "9    A9   B9   C9   D9\n",
      "10  A10  B10  C10  D10\n",
      "11  A11  B11  C11  D11\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes\n",
    "#\n",
    "# - Argument must be a list of DataFrames or Series, or a dict\n",
    "# - In this example all dataframes have the same columns and non-overlapping\n",
    "################################################################################\n",
    "result = pd.concat([df1, df2, df3])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        A    B    C    D\n",
      "x 0    A0   B0   C0   D0\n",
      "  1    A1   B1   C1   D1\n",
      "  2    A2   B2   C2   D2\n",
      "  3    A3   B3   C3   D3\n",
      "y 4    A4   B4   C4   D4\n",
      "  5    A5   B5   C5   D5\n",
      "  6    A6   B6   C6   D6\n",
      "  7    A7   B7   C7   D7\n",
      "z 8    A8   B8   C8   D8\n",
      "  9    A9   B9   C9   D9\n",
      "  10  A10  B10  C10  D10\n",
      "  11  A11  B11  C11  D11\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes\n",
    "#\n",
    "# - Can attach a distinguishing label for each constituent dataframe now we \n",
    "#     will have a multiindex\n",
    "# - Concat makes a full copy of the data\n",
    "################################################################################\n",
    "result = pd.concat([df1, df2, df3], keys=['x', 'y', 'z'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A   B    C   D    F\n",
      "0   A0  B0   C0  D0  NaN\n",
      "1   A1  B1   C1  D1  NaN\n",
      "2   A2  B2   C2  D2  NaN\n",
      "3   A3  B3   C3  D3  NaN\n",
      "2  NaN  B2  NaN  D2   F2\n",
      "3  NaN  B3  NaN  D3   F3\n",
      "6  NaN  B6  NaN  D6   F6\n",
      "7  NaN  B7  NaN  D7   F7\n",
      "\n",
      "\n",
      "     A    B    C    D    B    D    F\n",
      "0   A0   B0   C0   D0  NaN  NaN  NaN\n",
      "1   A1   B1   C1   D1  NaN  NaN  NaN\n",
      "2   A2   B2   C2   D2   B2   D2   F2\n",
      "3   A3   B3   C3   D3   B3   D3   F3\n",
      "6  NaN  NaN  NaN  NaN   B6   D6   F6\n",
      "7  NaN  NaN  NaN  NaN   B7   D7   F7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casey/coding_interview/interview_venv/lib/python3.5/site-packages/ipykernel_launcher.py:13: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes\n",
    "#\n",
    "# - The default merge method is 'outer' meaning that it will use the union of \n",
    "#     all keys in both dataframes\n",
    "# - Note that with an outer join it fills all missing fields with nans\n",
    "################################################################################\n",
    "df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "                    'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "                    'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "                   index=[2, 3, 6, 7])\n",
    "# Concatenate along rows (i.e. vertical stacking)\n",
    "result = pd.concat([df1, df4], axis=0)\n",
    "print(result)\n",
    "print('\\n')\n",
    "# Concatenate along columns (i.e. horizontal stacking)\n",
    "result = pd.concat([df1, df4], axis=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    B   D\n",
      "0  B0  D0\n",
      "1  B1  D1\n",
      "2  B2  D2\n",
      "3  B3  D3\n",
      "2  B2  D2\n",
      "3  B3  D3\n",
      "6  B6  D6\n",
      "7  B7  D7\n",
      "\n",
      "\n",
      "    A   B   C   D   B   D   F\n",
      "2  A2  B2  C2  D2  B2  D2  F2\n",
      "3  A3  B3  C3  D3  B3  D3  F3\n",
      "\n",
      "\n",
      "    A   B   C   D    B    D    F\n",
      "0  A0  B0  C0  D0  NaN  NaN  NaN\n",
      "1  A1  B1  C1  D1  NaN  NaN  NaN\n",
      "2  A2  B2  C2  D2   B2   D2   F2\n",
      "3  A3  B3  C3  D3   B3   D3   F3\n",
      "\n",
      "\n",
      "    B   D   F    A    B    C    D\n",
      "2  B2  D2  F2   A2   B2   C2   D2\n",
      "3  B3  D3  F3   A3   B3   C3   D3\n",
      "6  B6  D6  F6  NaN  NaN  NaN  NaN\n",
      "7  B7  D7  F7  NaN  NaN  NaN  NaN\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes - Inner Joins\n",
    "#\n",
    "# - A join of inner only returns the columns and rows that can be filled in\n",
    "#     completely, i.e. the intersection\n",
    "################################################################################\n",
    "df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "                    'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "                    'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "                   index=[2, 3, 6, 7])\n",
    "# Concatenate along rows (i.e. vertical stacking)\n",
    "# Drops columns A, C since the are not present in df4, it drops F not in df1\n",
    "result = pd.concat([df1, df4], join='inner', axis=0)\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Concatenate along columns (i.e. horizontal stacking)\n",
    "# Drops rows 0, 1, not in df4 and 6, 7 not in df1\n",
    "result = pd.concat([df1, df4], join='inner', axis=1)\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Concatenate along columns (i.e. horizontal stacking)\n",
    "# We can perform something between an inner and an outer join by specifying we\n",
    "# want to use only the keys from one but not the other (as opposed to an outer\n",
    "# join which uses the union)\n",
    "result = pd.concat([df1, df4], axis=1, join_axes=[df1.index])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "result = pd.concat([df4, df1], axis=1, join_axes=[df4.index])\n",
    "print(result)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A   B    C   D    F\n",
      "0   A0  B0   C0  D0  NaN\n",
      "1   A1  B1   C1  D1  NaN\n",
      "2   A2  B2   C2  D2  NaN\n",
      "3   A3  B3   C3  D3  NaN\n",
      "4  NaN  B2  NaN  D2   F2\n",
      "5  NaN  B3  NaN  D3   F3\n",
      "6  NaN  B6  NaN  D6   F6\n",
      "7  NaN  B7  NaN  D7   F7\n",
      "\n",
      "\n",
      "     0    1    2    3    4    5    6\n",
      "0   A0   B0   C0   D0  NaN  NaN  NaN\n",
      "1   A1   B1   C1   D1  NaN  NaN  NaN\n",
      "2   A2   B2   C2   D2   B2   D2   F2\n",
      "3   A3   B3   C3   D3   B3   D3   F3\n",
      "6  NaN  NaN  NaN  NaN   B6   D6   F6\n",
      "7  NaN  NaN  NaN  NaN   B7   D7   F7\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casey/coding_interview/interview_venv/lib/python3.5/site-packages/ipykernel_launcher.py:12: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes - resetting index\n",
    "#\n",
    "# - Can reset index and make sequential\n",
    "################################################################################\n",
    "df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "                    'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "                    'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "                   index=[2, 3, 6, 7])\n",
    "# Concatenate along rows (i.e. vertical stacking)\n",
    "# Resets row numbers\n",
    "result = pd.concat([df1, df4], axis=0, ignore_index=True)\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Concatenate along columns (i.e. horizontal stacking)\n",
    "# Resets column names\n",
    "result = pd.concat([df1, df4], axis=1, ignore_index=True)\n",
    "print(result)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,\n",
    "         left_index=False, right_index=False, sort=True,\n",
    "         suffixes=('_x', '_y'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B key   C   D\n",
      "0  A0  B0  K0  C0  D0\n",
      "1  A1  B1  K1  C1  D1\n",
      "2  A2  B2  K2  C2  D2\n",
      "3  A3  B3  K3  C3  D3\n",
      "\n",
      "\n",
      "    C   D key   A   B\n",
      "0  C0  D0  K0  A0  B0\n",
      "1  C1  D1  K1  A1  B1\n",
      "2  C2  D2  K2  A2  B2\n",
      "3  C3  D3  K3  A3  B3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes - Merging on common column one-to-one\n",
    "#\n",
    "# - Think about merging as stitching or mappings\n",
    "# - The default join is INNER\n",
    "################################################################################\n",
    "table1 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                       'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                       'B': ['B0', 'B1', 'B2', 'B3']})\n",
    " \n",
    "\n",
    "table2 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                       'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                       'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "# Merging on common column  'key'\n",
    "result = pd.merge(left=table1, right=table2, on='key')\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Merging on common column  'key' in reverse order\n",
    "# Since the keys are one-to-one these are the same (though the columns are permuted)\n",
    "result = pd.merge(left=table2, right=table1, on='key')\n",
    "print(result)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B key1 key2\n",
      "0  A0  B0   K0   K0\n",
      "1  A1  B1   K0   K1\n",
      "2  A2  B2   K1   K0\n",
      "3  A3  B3   K2   K1\n",
      "\n",
      "\n",
      "    C   D key1 key2\n",
      "0  C0  D0   K0   K0\n",
      "1  C1  D1   K1   K0\n",
      "2  C2  D2   K1   K0\n",
      "3  C3  D3   K2   K0\n",
      "\n",
      "\n",
      "    A   B key1 key2_x   C   D key2_y\n",
      "0  A0  B0   K0     K0  C0  D0     K0\n",
      "1  A1  B1   K0     K1  C0  D0     K0\n",
      "2  A2  B2   K1     K0  C1  D1     K0\n",
      "3  A2  B2   K1     K0  C2  D2     K0\n",
      "4  A3  B3   K2     K1  C3  D3     K0\n",
      "\n",
      "\n",
      "    C   D key1 key2_x   A   B key2_y\n",
      "0  C0  D0   K0     K0  A0  B0     K0\n",
      "1  C0  D0   K0     K0  A1  B1     K1\n",
      "2  C1  D1   K1     K0  A2  B2     K0\n",
      "3  C2  D2   K1     K0  A2  B2     K0\n",
      "4  C3  D3   K2     K0  A3  B3     K1\n",
      "\n",
      "\n",
      "    A   B key1 key2   C   D\n",
      "0  A0  B0   K0   K0  C0  D0\n",
      "1  A2  B2   K1   K0  C1  D1\n",
      "2  A2  B2   K1   K0  C2  D2\n",
      "\n",
      "\n",
      "    C   D key1 key2   A   B\n",
      "0  C0  D0   K0   K0  A0  B0\n",
      "1  C1  D1   K1   K0  A2  B2\n",
      "2  C2  D2   K1   K0  A2  B2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes - Merging on multiple columns\n",
    "#\n",
    "# - The domain of the mapping is the left key, return all entries in right table\n",
    "#     that match that key\n",
    "# - If there are common columns in both tables which are not joined on then they\n",
    "#     will be added but with suffixes '_x' for the left and '_y' for the right\n",
    "################################################################################\n",
    "\n",
    "table1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']}) \n",
    "\n",
    "table2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                      'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                      'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "print(table1)\n",
    "print('\\n')\n",
    "print(table2)\n",
    "print('\\n')\n",
    "\n",
    "# Join on single key\n",
    "result = pd.merge(left=table1, right=table2, on=['key1'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Note that the join is commutative since we are performing an inner join\n",
    "# The only difference is the suffixes added on the non-joined common column\n",
    "# key2\n",
    "result = pd.merge(left=table2, right=table1, on=['key1'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Join on multiple keys means that both keys have to match both keys in\n",
    "# the target table. So, since table2 has no entry with (key1, key2) = (K0, K1)\n",
    "# this is not entered into the resulting (since this is an inner join)\n",
    "result = pd.merge(left=table1, right=table2, on=['key1', 'key2'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "result = pd.merge(left=table2, right=table1, on=['key1', 'key2'])\n",
    "print(result)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B key1 key2    C    D\n",
      "0   A0   B0   K0   K0   C0   D0\n",
      "1   A1   B1   K0   K1  NaN  NaN\n",
      "2   A2   B2   K1   K0   C1   D1\n",
      "3   A2   B2   K1   K0   C2   D2\n",
      "4   A3   B3   K2   K1  NaN  NaN\n",
      "5  NaN  NaN   K2   K0   C3   D3\n",
      "\n",
      "\n",
      "     C    D key1 key2    A    B\n",
      "0   C0   D0   K0   K0   A0   B0\n",
      "1   C1   D1   K1   K0   A2   B2\n",
      "2   C2   D2   K1   K0   A2   B2\n",
      "3   C3   D3   K2   K0  NaN  NaN\n",
      "4  NaN  NaN   K0   K1   A1   B1\n",
      "5  NaN  NaN   K2   K1   A3   B3\n",
      "\n",
      "\n",
      "    A   B key1 key2_x   C   D key2_y\n",
      "0  A0  B0   K0     K0  C0  D0     K0\n",
      "1  A1  B1   K0     K1  C0  D0     K0\n",
      "2  A2  B2   K1     K0  C1  D1     K0\n",
      "3  A2  B2   K1     K0  C2  D2     K0\n",
      "4  A3  B3   K2     K1  C3  D3     K0\n",
      "\n",
      "\n",
      "    C   D key1 key2_x   A   B key2_y\n",
      "0  C0  D0   K0     K0  A0  B0     K0\n",
      "1  C0  D0   K0     K0  A1  B1     K1\n",
      "2  C1  D1   K1     K0  A2  B2     K0\n",
      "3  C2  D2   K1     K0  A2  B2     K0\n",
      "4  C3  D3   K2     K0  A3  B3     K1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes - Full Outer Join\n",
    "#\n",
    "# - builds table with union of all keys from both left and right tables\n",
    "################################################################################\n",
    "\n",
    "table1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']}) \n",
    "\n",
    "table2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                      'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                      'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "# Table will include all pairs from both left and right tables:\n",
    "#  From left:  (K0, K0), (K0, K1), (K1, K0), (K2, K1)\n",
    "#  From right: (K0, K0), (K1, K0), (K1, K0), (K2, K0)\n",
    "# All elements which do not have a counterpart will be filled with NaNs\n",
    "result = pd.merge(left=table1, right=table2, how='outer', on=['key1', 'key2'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Note that up to column ordering the two tables are the same\n",
    "result = pd.merge(left=table2, right=table1, how='outer', on=['key1', 'key2'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "result = pd.merge(left=table1, right=table2, how='outer', on=['key1'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Note that up to column ordering the two tables are the same\n",
    "result = pd.merge(left=table2, right=table1, how='outer', on=['key1'])\n",
    "print(result)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B key1 key2    C    D\n",
      "0  A0  B0   K0   K0   C0   D0\n",
      "1  A1  B1   K0   K1  NaN  NaN\n",
      "2  A2  B2   K1   K0   C1   D1\n",
      "3  A2  B2   K1   K0   C2   D2\n",
      "4  A3  B3   K2   K1  NaN  NaN\n",
      "\n",
      "\n",
      "    C   D key1 key2    A    B\n",
      "0  C0  D0   K0   K0   A0   B0\n",
      "1  C1  D1   K1   K0   A2   B2\n",
      "2  C2  D2   K1   K0   A2   B2\n",
      "3  C3  D3   K2   K0  NaN  NaN\n",
      "\n",
      "\n",
      "     A    B key1 key2   C   D\n",
      "0   A0   B0   K0   K0  C0  D0\n",
      "1   A2   B2   K1   K0  C1  D1\n",
      "2   A2   B2   K1   K0  C2  D2\n",
      "3  NaN  NaN   K2   K0  C3  D3\n",
      "\n",
      "\n",
      "     C    D key1 key2   A   B\n",
      "0   C0   D0   K0   K0  A0  B0\n",
      "1   C1   D1   K1   K0  A2  B2\n",
      "2   C2   D2   K1   K0  A2  B2\n",
      "3  NaN  NaN   K0   K1  A1  B1\n",
      "4  NaN  NaN   K2   K1  A3  B3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes - Left/Right Outer Join\n",
    "#\n",
    "# - Builds table using all of the keys in either the left or right table\n",
    "################################################################################\n",
    "\n",
    "table1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']}) \n",
    "\n",
    "table2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                      'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                      'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "# This will have all of the keys from the left table. If there is no corresponding\n",
    "# element in the right table, they will be filled with NaNs. Also, a left key can\n",
    "# be duplicated if there are multiple entries in the right table with the same key\n",
    "result = pd.merge(left=table1, right=table2, how='left', on=['key1', 'key2'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Note that this is NON-COMMUTATIVE\n",
    "result = pd.merge(left=table2, right=table1, how='left', on=['key1', 'key2'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# This will have all of the keys in the right table\n",
    "result = pd.merge(left=table1, right=table2, how='right', on=['key1', 'key2'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Note however that left<->right and table1<->table2 is commutative\n",
    "result = pd.merge(left=table2, right=table1, how='right', on=['key1', 'key2'])\n",
    "print(result)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join is really just a shorthand for merging on the indexes of the two tables by default. However, you can include a column argument to join to match a column in the left to an index on the right.\n",
    "i.e. the two are the same\n",
    "\n",
    "```python\n",
    "left.join(right, on=key_or_keys)\n",
    "pd.merge(left=left, right=right, left_on=key_or_keys, right_index=True, how='left')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B key    C    D\n",
      "0  A0  B0  K0  NaN  NaN\n",
      "1  A1  B1  K1  NaN  NaN\n",
      "2  A2  B2  K0  NaN  NaN\n",
      "3  A3  B3  K1  NaN  NaN\n",
      "\n",
      "\n",
      "    A   B key   C   D\n",
      "0  A0  B0  K0  C0  D0\n",
      "1  A1  B1  K1  C1  D1\n",
      "2  A2  B2  K0  C0  D0\n",
      "3  A3  B3  K1  C1  D1\n",
      "\n",
      "\n",
      "  A_l B_l key_l    A    B  key\n",
      "0  A0  B0    K0   E0   D0   K0\n",
      "1  A1  B1    K1   E1   D1   K1\n",
      "2  A2  B2    K0   E2   D2   K1\n",
      "3  A3  B3    K1  NaN  NaN  NaN\n",
      "\n",
      "\n",
      "    A   B key_l    F    G key_r\n",
      "0  A0  B0    K0   F0   G0    K0\n",
      "1  A1  B1    K1   F1   G1    K1\n",
      "2  A2  B2    K0   F2   G2    K1\n",
      "3  A3  B3    K1  NaN  NaN   NaN\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes - .join()\n",
    "#\n",
    "# - Shorthand designed for joining on indexes\n",
    "# - Default is a left outer join\n",
    "################################################################################\n",
    "\n",
    "table1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                       'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                       'key': ['K0', 'K1', 'K0', 'K1']})\n",
    "\n",
    "table2 = pd.DataFrame({'C': ['C0', 'C1'],\n",
    "                       'D': ['D0', 'D1']},\n",
    "                       index=['K0', 'K1'])\n",
    "\n",
    "table3 = pd.DataFrame({'A': ['E0', 'E1', 'E2'],\n",
    "                       'B': ['D0', 'D1', 'D2'],\n",
    "                       'key': ['K0', 'K1', 'K1',]})\n",
    "\n",
    "table4 = pd.DataFrame({'F': ['F0', 'F1', 'F2'],\n",
    "                       'G': ['G0', 'G1', 'G2'],\n",
    "                       'key': ['K0', 'K1', 'K1',]})\n",
    "\n",
    "# Note that since table 2's index is not a set of integers, but a set of strings\n",
    "# So, when it attempts to join, it will try to join on their indexes, but it\n",
    "# can't match any so all of right columns are filled with NaNs\n",
    "result = table1.join(table2)\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Now we tell it to instead join on table1's column='key' which finds matches in\n",
    "# table2's index\n",
    "result = table1.join(table2, on='key')\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Here will be able to match their indexes since they are both just row numbers.\n",
    "# However, the tables have columns with the same name, so we need to specify what\n",
    "# suffixes we want to add to the left or right column names to distinguish them\n",
    "result = table1.join(table3, lsuffix='_l')\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "result = table1.join(table4, lsuffix='_l', rsuffix='_r')\n",
    "print(result)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "?table1.join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mock Question from E-mail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An attendance log for every student in a school district ```attendance_events```:\n",
    "\n",
    "| date | student_id | attendance |\n",
    "|:----:|:----------:|:----------:|\n",
    "|      |            |            |\n",
    "\n",
    "A summary table with demographics for each student in the district ```all_students```: \n",
    "\n",
    "|student_id | school_id | grade_level | date_of_birth | hometown |\n",
    "|-----------|-----------|-------------|---------------|----------|\n",
    "\n",
    "Using this data, you could answer questions like the following:\n",
    "\n",
    "* What percent of students attend school on their birthday?\n",
    "* Which grade level had the largest drop in attendance between yesterday and today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Functions used to generate mock data simulating the tables given above.\n",
    "\n",
    "n_students = 1000\n",
    "n_days = 10\n",
    "start_date = '2017-09-01'\n",
    "end_date = '2018-06-15'\n",
    "\n",
    "################################################################################\n",
    "# Attendance Table                                                             #\n",
    "################################################################################\n",
    "def _make_event_dates(n_students, start_date, end_date):\n",
    "    dr = pd.date_range(start_date, end_date)\n",
    "    dates = []\n",
    "    for day in dr:\n",
    "        dates.extend([day] * n_students)\n",
    "    return dates\n",
    "\n",
    "def _make_student_ids(n_students, n_days=None):\n",
    "    student_ids = [xx for xx in range(100, 100 + n_students)]\n",
    "    if n_days is not None:\n",
    "        student_ids = student_ids * n_days\n",
    "    return student_ids\n",
    "\n",
    "def _make_attendance(n_students, n_days):\n",
    "    return list(np.random.choice(2, n_students, p=[0.3, 0.7])) * n_days\n",
    "\n",
    "def build_attendance_events(n_students, start_date, end_date):\n",
    "    columns = ['date', 'student_id', 'attendance']\n",
    "    n_days = len(pd.date_range(start_date, end_date))\n",
    "    \n",
    "    dates       = _make_event_dates(n_students, start_date, end_date)\n",
    "    student_ids = _make_student_ids(n_students, n_days)\n",
    "    attendance  = _make_attendance(n_students, n_days)\n",
    "    data = [xx for xx in zip(dates, student_ids, attendance)]\n",
    "    \n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "    return df\n",
    "\n",
    "################################################################################\n",
    "# District All Students Table                                                  #\n",
    "################################################################################\n",
    "def _make_school_ids(n_students):\n",
    "    schools = ['South River High School',\n",
    "               'New Brunswick High School',\n",
    "               'East Brunswick High School',\n",
    "               'Edison High School']\n",
    "    return list(np.random.choice(schools, n_students))\n",
    "\n",
    "def _make_grade_levels(n_students):\n",
    "    grades = ['Freshman', 'Sophomore', 'Junior', 'Senior']\n",
    "    return list(np.random.choice(grades, n_students))\n",
    "    \n",
    "def _make_DOBs(grade_levels):\n",
    "    birth_years = {\n",
    "        'Freshman': 2005,\n",
    "        'Sophomore': 2004,\n",
    "        'Junior': 2003,\n",
    "        'Senior': 2002\n",
    "    }\n",
    "    years = [birth_years[xx] for xx in grade_levels]\n",
    "    months = list(np.random.choice(np.arange(1,13), len(grade_levels)))\n",
    "    days = list(np.random.choice(np.arange(1,29), len(grade_levels)))\n",
    "    DOBs = pd.to_datetime(['{}-{}-{}'.format(*dd) for dd in zip(months, days, years)])\n",
    "    return DOBs\n",
    "\n",
    "def _make_hometowns(school_ids):\n",
    "    hometowns = [school.split('High School')[0].strip() for school in school_ids]\n",
    "    return hometowns\n",
    "    \n",
    "\n",
    "def build_all_students(n_students):\n",
    "    student_ids  = _make_student_ids(n_students)\n",
    "    school_ids   = _make_school_ids(n_students)\n",
    "    grade_levels = _make_grade_levels(n_students)\n",
    "    DOBs         = _make_DOBs(grade_levels)\n",
    "    hometowns    = _make_hometowns(school_ids)\n",
    "    \n",
    "    columns = ['student_id', 'school_id', 'grade_level', 'date_of_birth', 'hometown']\n",
    "    data = [xx for xx in zip(student_ids, school_ids, grade_levels, DOBs, hometowns)]\n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "    return df\n",
    "    \n",
    "\n",
    "attendance_events = build_attendance_events(n_students, start_date, end_date)\n",
    "all_students = build_all_students(n_students=n_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>student_id</th>\n",
       "      <th>attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  student_id  attendance\n",
       "0 2017-09-01         100           1\n",
       "1 2017-09-01         101           1\n",
       "2 2017-09-01         102           1\n",
       "3 2017-09-01         103           0\n",
       "4 2017-09-01         104           0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>school_id</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>hometown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>New Brunswick High School</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>2005-09-12</td>\n",
       "      <td>New Brunswick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>New Brunswick High School</td>\n",
       "      <td>Sophomore</td>\n",
       "      <td>2004-09-23</td>\n",
       "      <td>New Brunswick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>South River High School</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>2005-06-24</td>\n",
       "      <td>South River</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>East Brunswick High School</td>\n",
       "      <td>Senior</td>\n",
       "      <td>2002-09-05</td>\n",
       "      <td>East Brunswick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>South River High School</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>2005-12-14</td>\n",
       "      <td>South River</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_id                   school_id grade_level date_of_birth  \\\n",
       "0         100   New Brunswick High School    Freshman    2005-09-12   \n",
       "1         101   New Brunswick High School   Sophomore    2004-09-23   \n",
       "2         102     South River High School    Freshman    2005-06-24   \n",
       "3         103  East Brunswick High School      Senior    2002-09-05   \n",
       "4         104     South River High School    Freshman    2005-12-14   \n",
       "\n",
       "         hometown  \n",
       "0   New Brunswick  \n",
       "1   New Brunswick  \n",
       "2     South River  \n",
       "3  East Brunswick  \n",
       "4     South River  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_students.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What percent of students attend school on their birthday?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>student_id</th>\n",
       "      <th>attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287970</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287971</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287972</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287973</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287974</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287975</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287976</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1076</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287977</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287978</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287980</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287981</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1081</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287982</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287983</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1083</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287984</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287985</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287986</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287987</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287988</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287989</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287990</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287991</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287992</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287993</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287994</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287995</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287996</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287997</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287998</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287999</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1099</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  student_id  attendance\n",
       "0      2017-09-01         100           1\n",
       "1      2017-09-01         101           1\n",
       "2      2017-09-01         102           1\n",
       "3      2017-09-01         103           0\n",
       "4      2017-09-01         104           0\n",
       "5      2017-09-01         105           0\n",
       "6      2017-09-01         106           0\n",
       "7      2017-09-01         107           1\n",
       "8      2017-09-01         108           1\n",
       "9      2017-09-01         109           1\n",
       "10     2017-09-01         110           1\n",
       "11     2017-09-01         111           0\n",
       "12     2017-09-01         112           0\n",
       "13     2017-09-01         113           1\n",
       "14     2017-09-01         114           0\n",
       "15     2017-09-01         115           0\n",
       "16     2017-09-01         116           1\n",
       "17     2017-09-01         117           1\n",
       "18     2017-09-01         118           0\n",
       "19     2017-09-01         119           1\n",
       "20     2017-09-01         120           0\n",
       "21     2017-09-01         121           0\n",
       "22     2017-09-01         122           0\n",
       "23     2017-09-01         123           1\n",
       "24     2017-09-01         124           0\n",
       "25     2017-09-01         125           1\n",
       "26     2017-09-01         126           1\n",
       "27     2017-09-01         127           1\n",
       "28     2017-09-01         128           1\n",
       "29     2017-09-01         129           1\n",
       "...           ...         ...         ...\n",
       "287970 2018-06-15        1070           0\n",
       "287971 2018-06-15        1071           1\n",
       "287972 2018-06-15        1072           1\n",
       "287973 2018-06-15        1073           0\n",
       "287974 2018-06-15        1074           1\n",
       "287975 2018-06-15        1075           1\n",
       "287976 2018-06-15        1076           1\n",
       "287977 2018-06-15        1077           0\n",
       "287978 2018-06-15        1078           1\n",
       "287979 2018-06-15        1079           1\n",
       "287980 2018-06-15        1080           1\n",
       "287981 2018-06-15        1081           1\n",
       "287982 2018-06-15        1082           0\n",
       "287983 2018-06-15        1083           1\n",
       "287984 2018-06-15        1084           1\n",
       "287985 2018-06-15        1085           1\n",
       "287986 2018-06-15        1086           1\n",
       "287987 2018-06-15        1087           1\n",
       "287988 2018-06-15        1088           1\n",
       "287989 2018-06-15        1089           1\n",
       "287990 2018-06-15        1090           0\n",
       "287991 2018-06-15        1091           1\n",
       "287992 2018-06-15        1092           1\n",
       "287993 2018-06-15        1093           1\n",
       "287994 2018-06-15        1094           1\n",
       "287995 2018-06-15        1095           1\n",
       "287996 2018-06-15        1096           0\n",
       "287997 2018-06-15        1097           1\n",
       "287998 2018-06-15        1098           0\n",
       "287999 2018-06-15        1099           1\n",
       "\n",
       "[288000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevant Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pandas - Dates and Times](#pandas-dates)\n",
    "\n",
    "[Pandas - Merge, Join, Concatenate](#pandas-join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview_prep",
   "language": "python",
   "name": "interview_prep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
