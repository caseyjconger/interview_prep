{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for Facebook Technical Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are my notes for preparing for the technical portion of the interview. To simulate interview conditions, I wrote all code in markdown mode only converting the cells to executable after I felt comfortable they were correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Exercises](#exercises)\n",
    "\n",
    "[Notes](#notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises <a id='exercises'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mock Question from E-mail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An attendance log for every student in a school district ```attendance_events```:\n",
    "\n",
    "| date | student_id | attendance |\n",
    "|:----:|:----------:|:----------:|\n",
    "|      |            |            |\n",
    "\n",
    "A summary table with demographics for each student in the district ```all_students```: \n",
    "\n",
    "|student_id | school_id | grade_level | date_of_birth | hometown |\n",
    "|-----------|-----------|-------------|---------------|----------|\n",
    "\n",
    "Using this data, you could answer questions like the following:\n",
    "\n",
    "* What percent of students attend school on their birthday?\n",
    "* Which grade level had the largest drop in attendance between yesterday and today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "################################################################################\n",
    "# Functions used to generate mock data simulating the tables given above.      #\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "n_students = 1000\n",
    "n_days = 10\n",
    "start_date = '2017-09-01'\n",
    "end_date = '2018-06-15'\n",
    "\n",
    "################################################################################\n",
    "# Attendance Table                                                             #\n",
    "################################################################################\n",
    "def _make_attendance_dates(n_students, start_date, end_date):\n",
    "    dr = pd.date_range(start_date, end_date)\n",
    "    dates = []\n",
    "    for day in dr:\n",
    "        dates.extend([day] * n_students)\n",
    "    return dates\n",
    "\n",
    "def _make_student_ids(n_students, n_days=None):\n",
    "    student_ids = [xx for xx in range(100, 100 + n_students)]\n",
    "    if n_days is not None:\n",
    "        student_ids = student_ids * n_days\n",
    "    return student_ids\n",
    "\n",
    "def _make_attendance(n_students, n_days):\n",
    "    attendance = []\n",
    "    for _ in range(0, n_days):\n",
    "        prob = np.random.rand()\n",
    "        this_attendance = list(np.random.choice(2, n_students, p=[prob, 1.-prob]))\n",
    "        attendance.extend(this_attendance)\n",
    "    return attendance\n",
    "\n",
    "def build_attendance(n_students, start_date, end_date):\n",
    "    columns = ['date', 'student_id', 'attendance']\n",
    "    n_days = len(pd.date_range(start_date, end_date))\n",
    "    \n",
    "    dates       = _make_attendance_dates(n_students, start_date, end_date)\n",
    "    student_ids = _make_student_ids(n_students, n_days)\n",
    "    attendance  = _make_attendance(n_students, n_days)\n",
    "    data = [xx for xx in zip(dates, student_ids, attendance)]\n",
    "    \n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "    return df\n",
    "\n",
    "################################################################################\n",
    "# District All Students Table                                                  #\n",
    "################################################################################\n",
    "def _make_school_ids(n_students):\n",
    "    schools = ['South River High School',\n",
    "               'New Brunswick High School',\n",
    "               'East Brunswick High School',\n",
    "               'Edison High School']\n",
    "    return list(np.random.choice(schools, n_students))\n",
    "\n",
    "def _make_grade_levels(n_students):\n",
    "    grades = ['Freshman', 'Sophomore', 'Junior', 'Senior']\n",
    "    return list(np.random.choice(grades, n_students))\n",
    "    \n",
    "def _make_DOBs(grade_levels):\n",
    "    birth_years = {\n",
    "        'Freshman': 2005,\n",
    "        'Sophomore': 2004,\n",
    "        'Junior': 2003,\n",
    "        'Senior': 2002\n",
    "    }\n",
    "    years = [birth_years[xx] for xx in grade_levels]\n",
    "    months = list(np.random.choice(np.arange(1,13), len(grade_levels)))\n",
    "    days = list(np.random.choice(np.arange(1,29), len(grade_levels)))\n",
    "    DOBs = pd.to_datetime(['{}-{}-{}'.format(*dd) for dd in zip(months, days, years)])\n",
    "    return DOBs\n",
    "\n",
    "def _make_hometowns(school_ids):\n",
    "    hometowns = [school.split('High School')[0].strip() for school in school_ids]\n",
    "    return hometowns\n",
    "    \n",
    "\n",
    "def build_all_students(n_students):\n",
    "    student_ids  = _make_student_ids(n_students)\n",
    "    school_ids   = _make_school_ids(n_students)\n",
    "    grade_levels = _make_grade_levels(n_students)\n",
    "    DOBs         = _make_DOBs(grade_levels)\n",
    "    hometowns    = _make_hometowns(school_ids)\n",
    "    \n",
    "    columns = ['student_id', 'school_id', 'grade_level', 'date_of_birth', 'hometown']\n",
    "    data = [xx for xx in zip(student_ids, school_ids, grade_levels, DOBs, hometowns)]\n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "    return df\n",
    "    \n",
    "\n",
    "attendance = build_attendance(n_students, start_date, end_date)\n",
    "all_students = build_all_students(n_students=n_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>student_id</th>\n",
       "      <th>attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287995</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287996</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287997</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287998</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287999</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>1099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  student_id  attendance\n",
       "287995 2018-06-15        1095           1\n",
       "287996 2018-06-15        1096           1\n",
       "287997 2018-06-15        1097           1\n",
       "287998 2018-06-15        1098           1\n",
       "287999 2018-06-15        1099           0"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>school_id</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>hometown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>South River High School</td>\n",
       "      <td>Sophomore</td>\n",
       "      <td>2004-07-12</td>\n",
       "      <td>South River</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>East Brunswick High School</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>2005-09-09</td>\n",
       "      <td>East Brunswick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>East Brunswick High School</td>\n",
       "      <td>Junior</td>\n",
       "      <td>2003-05-19</td>\n",
       "      <td>East Brunswick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>Edison High School</td>\n",
       "      <td>Senior</td>\n",
       "      <td>2002-06-28</td>\n",
       "      <td>Edison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>South River High School</td>\n",
       "      <td>Junior</td>\n",
       "      <td>2003-07-05</td>\n",
       "      <td>South River</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_id                   school_id grade_level date_of_birth  \\\n",
       "0         100     South River High School   Sophomore    2004-07-12   \n",
       "1         101  East Brunswick High School    Freshman    2005-09-09   \n",
       "2         102  East Brunswick High School      Junior    2003-05-19   \n",
       "3         103          Edison High School      Senior    2002-06-28   \n",
       "4         104     South River High School      Junior    2003-07-05   \n",
       "\n",
       "         hometown  \n",
       "0     South River  \n",
       "1  East Brunswick  \n",
       "2  East Brunswick  \n",
       "3          Edison  \n",
       "4     South River  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_students.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What percent of students attend school on their birthday?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.1"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_attendance = pd.merge(\n",
    "    left=attendance,\n",
    "    right=all_students,\n",
    "    how='inner',\n",
    "    on='student_id'\n",
    ")\n",
    "\n",
    "attended = (all_attendance['attendance'] == 1)\n",
    "\n",
    "attendance_month = all_attendance['date'].apply(lambda x: x.month)\n",
    "attendance_day = all_attendance['date'].apply(lambda x: x.day)\n",
    "birthday_month = all_attendance['date_of_birth'].apply(lambda x: x.month)\n",
    "birthday_day = all_attendance['date_of_birth'].apply(lambda x: x.day)\n",
    "\n",
    "on_birthday = (attendance_month == birthday_month) & (attendance_day == birthday_day)\n",
    "\n",
    "attended_on_birthday = all_attendance[attended & on_birthday]\n",
    "\n",
    "num_attended_on_birthday = float(attended_on_birthday.shape[0])\n",
    "num_total = float(all_students.shape[0])\n",
    "\n",
    "pct_attended_on_birthday = (num_attended_on_birthday / num_total) * 100.\n",
    "pct_attended_on_birthday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which grade level had the largest drop in attendance between yesterday and today?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_attendance = all_attendance[all_attendance['date'] == today]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sophomore'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = pd.to_datetime('2017-09-04')\n",
    "yesterday = pd.to_datetime('2017-09-03')\n",
    "\n",
    "def get_attendance(date):\n",
    "    date_attendance = all_attendance[all_attendance['date'] == date]\n",
    "    date_attendance = date_attendance[['grade_level', 'attendance']]\n",
    "    date_attendance = date_attendance[date_attendance['attendance'] == 1]\n",
    "    num_attended = date_attendance.groupby('grade_level').sum()\n",
    "    return num_attended\n",
    "\n",
    "today_attendance = get_attendance(today)\n",
    "yesterday_attendance = get_attendance(yesterday)\n",
    "\n",
    "drop_attendance = today_attendance - yesterday_attendance\n",
    "drop_attendance.idxmax()['attendance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeetCode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second/N-th Highest Salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question-description__3U1T\"><div><p>Write a SQL query to get the second highest salary from the <code>Employee</code> table.</p>\n",
    "\n",
    "<pre>+----+--------+\n",
    "| Id | Salary |\n",
    "+----+--------+\n",
    "| 1  | 100    |\n",
    "| 2  | 200    |\n",
    "| 3  | 300    |\n",
    "+----+--------+\n",
    "</pre>\n",
    "\n",
    "<p>For example, given the above Employee table, the query should return <code>200</code> as the second highest salary. If there is no second highest salary, then the query should return <code>null</code>.</p>\n",
    "\n",
    "<pre>+---------------------+\n",
    "| SecondHighestSalary |\n",
    "+---------------------+\n",
    "| 200                 |\n",
    "+---------------------+\n",
    "</pre>\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   salary\n",
      "0     300\n",
      "1     300\n",
      "2     100\n",
      "3     200\n",
      "4     400\n",
      "5     600\n",
      "6     800\n",
      "7     900\n",
      "8     900\n",
      "9     400\n",
      "(array([100, 200, 300, 400, 600, 800, 900]), 800)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "num_employees = 10\n",
    "\n",
    "def build_employee_table(num_employees):\n",
    "    salaries = np.random.choice(np.arange(100, 1000, 100), 10)\n",
    "    Employee = pd.DataFrame(salaries, columns=['salary'])\n",
    "    return Employee\n",
    "\n",
    "Employee = build_employee_table(num_employees)\n",
    "\n",
    "def get_nth_highest_salary(employee_table, n):\n",
    "    # Note: \n",
    "    #   * can use pd.unique() or Series.unique()\n",
    "    #   * for pd.unique() can pass it any array like object: Series, np.array, list\n",
    "    salaries = employee_table['salary'].unique()\n",
    "    \n",
    "    # Note: np.sort() returns a sorted copy\n",
    "    #   ndarray.sort() sorts in place\n",
    "    #   can't specify ascending/descneding\n",
    "    salaries_sort = np.sort(salaries)\n",
    "    return salaries_sort, salaries_sort[-n]\n",
    "    \n",
    "print(Employee)\n",
    "print(get_nth_highest_salary(Employee, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customers Who Never Order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question-detail\"><div class=\"question-description__3U1T\"><div><p>Suppose that a website contains two tables, the <code>Customers</code> table and the <code>Orders</code> table. Write a SQL query to find all customers who never order anything.</p>\n",
    "\n",
    "<p>Table: <code>Customers</code>.</p>\n",
    "\n",
    "<pre>+----+-------+\n",
    "| Id | Name  |\n",
    "+----+-------+\n",
    "| 1  | Joe   |\n",
    "| 2  | Henry |\n",
    "| 3  | Sam   |\n",
    "| 4  | Max   |\n",
    "+----+-------+\n",
    "</pre>\n",
    "\n",
    "<p>Table: <code>Orders</code>.</p>\n",
    "\n",
    "<pre>+----+------------+\n",
    "| Id | CustomerId |\n",
    "+----+------------+\n",
    "| 1  | 3          |\n",
    "| 2  | 1          |\n",
    "+----+------------+\n",
    "</pre>\n",
    "\n",
    "<p>Using the above tables as example, return the following:</p>\n",
    "\n",
    "<pre>+-----------+\n",
    "| Customers |\n",
    "+-----------+\n",
    "| Henry     |\n",
    "| Max       |\n",
    "+-----------+\n",
    "</pre>\n",
    "</div></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    Henry\n",
       "3      Max\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Notes:\n",
    "#   * Set index name after construction\n",
    "Customers = pd.DataFrame(\n",
    "    data=['Joe', 'Henry', 'Sam', 'Max'],\n",
    "    index=np.arange(1,5),\n",
    "    columns=['Name']\n",
    ")\n",
    "Customers.index.name = 'Id'\n",
    "\n",
    "Orders = pd.DataFrame(\n",
    "    data=[3, 1],\n",
    "    index=np.arange(1,3),\n",
    "    columns=['CustomerId']\n",
    ")\n",
    "\n",
    "Customer_Orders = pd.merge(\n",
    "    left=Orders,\n",
    "    right=Customers,\n",
    "    how='outer',\n",
    "    left_on=['CustomerId'],\n",
    "    right_on=['Id']\n",
    ")\n",
    "\n",
    "# To get nan's use pd.isnull()\n",
    "never_ordered = Customer_Orders[pd.isnull(Customer_Orders['CustomerId'])]['Name']\n",
    "never_ordered = Customer_Orders[Customer_Orders['CustomerId'].isna()]['Name']\n",
    "never_ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friend Requests I: Overall Acceptance Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question-area\"><div class=\"question-detail\"><div class=\"question-description__3U1T\"><div>In social network like Facebook or Twitter, people send friend requests and accept others’ requests as well. Now given two tables as below:<p></p>\n",
    "\n",
    "Table: <code>friend_request</code>\n",
    "<pre>| sender_id | send_to_id |request_date|\n",
    "|-----------|------------|------------|\n",
    "| 1         | 2          | 2016_06-01 |\n",
    "| 1         | 3          | 2016_06-01 |\n",
    "| 1         | 4          | 2016_06-01 |\n",
    "| 2         | 3          | 2016_06-02 |\n",
    "| 3         | 4          | 2016-06-09 |\n",
    "</pre><p></p>\n",
    "\n",
    "Table: <code>request_accepted</code>\n",
    "<pre>| requester_id | accepter_id |accept_date |\n",
    "|--------------|-------------|------------|\n",
    "| 1            | 2           | 2016_06-03 |\n",
    "| 1            | 3           | 2016-06-08 |\n",
    "| 2            | 3           | 2016-06-08 |\n",
    "| 3            | 4           | 2016-06-09 |\n",
    "| 3            | 4           | 2016-06-10 |\n",
    "</pre><p></p>\n",
    "\n",
    "Write a query to find the overall acceptance rate of requests rounded to 2 decimals, which is the number of acceptance divide the number of requests.<p></p>\n",
    "\n",
    "For the sample data above, your query should return the following result.<p></p>\n",
    "<pre>|accept_rate|\n",
    "|-----------|\n",
    "|       0.80|\n",
    "</pre><p></p>\n",
    "\n",
    "<b>Note:</b>\n",
    "<li>The accepted requests are not necessarily from the table <code>friend_request</code>. In this case, you just need to simply count the total accepted requests (no matter whether they are in the original requests), and divide it by the number of requests to get the acceptance rate.</li>\n",
    "<li>It is possible that a sender sends multiple requests to the same receiver, and a request could be accepted more than once. In this case, the ‘duplicated’ requests or acceptances are only counted once.</li>\n",
    "<li>If there is no requests at all, you should return 0.00 as the accept_rate. </li>\n",
    "<p></p>\n",
    "\n",
    "<b>Explanation:</b> There are 4 unique accepted requests, and there are 5 requests in total. So the rate is 0.80.<p></p>\n",
    "\n",
    "<b>Follow-up:</b><br>\n",
    "<li>Can you write a query to return the accept rate but for every month?</li>\n",
    "<li>How about the cumulative accept rate for every day?</li></div></div></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_friend_request():\n",
    "    friend_request = {\n",
    "        'sender_id':  [1, 1, 1, 2, 3],\n",
    "        'send_to_id': [2, 3, 4, 3, 4],\n",
    "        'request_date': pd.to_datetime([\n",
    "            '2016-06-01',\n",
    "            '2016-06-01',\n",
    "            '2016-06-01',\n",
    "            '2016-06-02',\n",
    "            '2016-06-09'\n",
    "        ])\n",
    "    }\n",
    "    return pd.DataFrame(friend_request)\n",
    "    \n",
    "def build_request_accepted():\n",
    "    request_accepted = {\n",
    "        'requester_id':  [1, 1, 2, 3, 3],\n",
    "        'accepter_id': [2, 3, 3, 4, 4],\n",
    "        'accept_date': pd.to_datetime([\n",
    "            '2016-06-03',\n",
    "            '2016-06-08',\n",
    "            '2016-06-08',\n",
    "            '2016-06-09',\n",
    "            '2016-06-10'\n",
    "        ])\n",
    "    }\n",
    "    return pd.DataFrame(request_accepted)\n",
    "    \n",
    "friend_request = build_friend_request()\n",
    "friend_request_unique = friend_request.drop_duplicates(subset=['sender_id', 'send_to_id'])\n",
    "\n",
    "request_accepted = build_request_accepted()\n",
    "request_accepted_unique = request_accepted.drop_duplicates(subset=['requester_id', 'accepter_id'])\n",
    "\n",
    "acceptance_rate = float(request_accepted_unique.shape[0]) / friend_request_unique.shape[0]\n",
    "\n",
    "acceptance_rate    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ra_month_day_counts\n",
      "6 3                   1.0\n",
      "  8                   2.0\n",
      "  9                   1.0\n",
      "7 10                  2.0\n",
      "8 10                  1.0\n",
      "      fr_month_day_counts\n",
      "6 1                   3.0\n",
      "  2                   1.0\n",
      "  9                   1.0\n",
      "7 2                   1.0\n",
      "  3                   1.0\n",
      "  10                  1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accept_rate</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accept_rate  day  month\n",
       "0          0.0    1      6\n",
       "1          0.0    2      6\n",
       "2          0.0    3      6\n",
       "3          0.0    8      6\n",
       "4          1.0    9      6\n",
       "5          0.0    2      7\n",
       "6          0.0    3      7\n",
       "7          2.0   10      7\n",
       "8          0.0   10      8"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Follow-Ups\n",
    "\n",
    "def build_friend_request():\n",
    "    friend_request = {\n",
    "        'sender_id':  [1, 1, 1, 2, 3, 5, 6, 5],\n",
    "        'send_to_id': [2, 3, 4, 3, 4, 4, 8, 6],\n",
    "        'request_date': pd.to_datetime([\n",
    "            '2016-06-01',\n",
    "            '2016-06-01',\n",
    "            '2016-06-01',\n",
    "            '2016-06-02',\n",
    "            '2016-06-09',\n",
    "            '2016-07-02',\n",
    "            '2016-07-03',\n",
    "            '2016-07-10'\n",
    "        ])\n",
    "    }\n",
    "    return pd.DataFrame(friend_request)\n",
    "    \n",
    "def build_request_accepted():\n",
    "    request_accepted = {\n",
    "        'requester_id':  [1, 1, 2, 3, 3, 8, 7, 6],\n",
    "        'accepter_id':   [2, 3, 3, 4, 4, 9, 5, 5],\n",
    "        'accept_date': pd.to_datetime([\n",
    "            '2016-06-03',\n",
    "            '2016-06-08',\n",
    "            '2016-06-08',\n",
    "            '2016-06-09',\n",
    "            '2016-06-10',\n",
    "            '2016-07-10',\n",
    "            '2016-07-10',\n",
    "            '2016-08-10'\n",
    "        ])\n",
    "    }\n",
    "    return pd.DataFrame(request_accepted)\n",
    "    \n",
    "fr = build_friend_request()\n",
    "fr_unique = fr.drop_duplicates(subset=['sender_id', 'send_to_id'])\n",
    "\n",
    "ra = build_request_accepted()\n",
    "ra_unique = ra.drop_duplicates(subset=['requester_id', 'accepter_id'])\n",
    "\n",
    "fr_unique.index = fr_unique.pop('request_date')\n",
    "ra_unique.index = ra_unique.pop('accept_date')\n",
    "\n",
    "# Group By Month & Day\n",
    "\n",
    "month_key = lambda x: x.month\n",
    "day_key = lambda x: x.day\n",
    "\n",
    "# Month\n",
    "fr_month_counts = fr_unique.groupby(by=[month_key]).count().pop('sender_id')\n",
    "fr_month_counts.name = 'fr_month_counts'\n",
    "fr_month_counts = pd.DataFrame(fr_month_counts.apply(float))\n",
    "\n",
    "ra_month_counts = ra_unique.groupby(by=[month_key]).count().pop('accepter_id')\n",
    "ra_month_counts.name = 'ra_month_counts'\n",
    "ra_month_counts = pd.DataFrame(ra_month_counts.apply(float))\n",
    "\n",
    "accept_rate_month = pd.merge(\n",
    "    left=ra_month_counts,\n",
    "    right=fr_month_counts,\n",
    "    how='outer',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "\n",
    "accept_rate_month['acceptance_rate'] = accept_rate_month.apply(lambda x: x['ra_month_counts'] / x['fr_month_counts'], axis=1)\n",
    "accept_rate_month = accept_rate_month.fillna(0.0)\n",
    "\n",
    "# Day\n",
    "fr_month_day_counts = fr_unique.groupby(by=[month_key, day_key]).count().pop('sender_id')\n",
    "fr_month_day_counts.name = 'fr_month_day_counts'\n",
    "fr_month_day_counts = pd.DataFrame(fr_month_day_counts.apply(float))\n",
    "\n",
    "ra_month_day_counts = ra_unique.groupby(by=[month_key, day_key]).count().pop('accepter_id')\n",
    "ra_month_day_counts.name = 'ra_month_day_counts'\n",
    "ra_month_day_counts = pd.DataFrame(ra_month_day_counts.apply(float))\n",
    "print(ra_month_day_counts)\n",
    "print(fr_month_day_counts)\n",
    "\n",
    "accept_rate_month_day = pd.merge(\n",
    "    left=ra_month_day_counts,\n",
    "    right=fr_month_day_counts,\n",
    "    how='outer',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "\n",
    "\n",
    "ar_md_dict = {}\n",
    "months = []\n",
    "days = []\n",
    "ar_list = []\n",
    "for row in accept_rate_month_day.iterrows():\n",
    "    this_month = row[0][0]\n",
    "    this_day = row[0][1]\n",
    "    this_fr = row[1].fr_month_day_counts\n",
    "    this_ra = row[1].ra_month_day_counts\n",
    "    this_accept_rate = this_ra / this_fr\n",
    "    months.append(this_month)\n",
    "    days.append(this_day)\n",
    "    ar_list.append(this_accept_rate)\n",
    "    \n",
    "ar_dict = {\n",
    "    'month': months,\n",
    "    'day': days,\n",
    "    'accept_rate': ar_list\n",
    "}\n",
    "\n",
    "accept_rate_month_day = pd.DataFrame(ar_dict).fillna(0)\n",
    "accept_rate_month_day\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6  1     0.0\n",
       "   2     0.0\n",
       "   3     0.0\n",
       "   8     0.0\n",
       "   9     1.0\n",
       "7  2     0.0\n",
       "   3     0.0\n",
       "   10    2.0\n",
       "8  10    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should have done it this way\n",
    "accept_rate_month_day = pd.merge(\n",
    "    left=ra_month_day_counts,\n",
    "    right=fr_month_day_counts,\n",
    "    how='outer',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "\n",
    "def get_md_arr(idx):\n",
    "    s = accept_rate_month_day.loc[idx]\n",
    "    return s.ra_month_day_counts / s.fr_month_day_counts\n",
    "accept_rate_month_day.apply(lambda x: get_md_arr(x.name), axis=1).fillna(0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevant Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pandas - Dates and Times](#pandas-dates)\n",
    "\n",
    "[Pandas - Merge, Join, Concatenate](#pandas-join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes <a id='notes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pandas-dates'></a> [**Pandas - Time Series / Date Functionality**](http://pandas.pydata.org/pandas-docs/version/0.23/timeseries.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uses the numpy ```datetime64``` and ```timedelta64``` datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" class=\"docutils\">\n",
    "<colgroup>\n",
    "<col width=\"15%\">\n",
    "<col width=\"27%\">\n",
    "<col width=\"58%\">\n",
    "</colgroup>\n",
    "\n",
    "<thead valign=\"bottom\">\n",
    "<tr class=\"row-odd\"><th class=\"head\">Class</th>\n",
    "<th class=\"head\">Remarks</th>\n",
    "<th class=\"head\">How to create</th>\n",
    "</tr>\n",
    "</thead><tbody valign=\"top\">\n",
    "<tr class=\"row-even\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">Timestamp</span></code></td>\n",
    "<td>Represents a single timestamp</td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">to_datetime</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">Timestamp</span></code></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></td>\n",
    "<td>Index of <code class=\"docutils literal notranslate\"><span class=\"pre\">Timestamp</span></code></td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">to_datetime</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">date_range</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">bdate_range</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">Period</span></code></td>\n",
    "<td>Represents a single time span</td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">Period</span></code></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">PeriodIndex</span></code></td>\n",
    "<td>Index of <code class=\"docutils literal notranslate\"><span class=\"pre\">Period</span></code></td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">period_range</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">PeriodIndex</span></code></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Both ```Timestamp``` and  ```Period``` objects can serve as an index. They are automatically cast into ```DatetimeIndex``` and ```PeriodIndex``` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casey/coding_interview/interview_venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   2009-07-31\n",
       "1   2010-01-10\n",
       "2          NaT\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Can convert from strings to date-like objects via pd.to_datetime\n",
    "pd.to_datetime(pd.Series(['Jul 31, 2009', '2010-01-10', None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2010-02-20', '2010-02-21', '2010-02-22', '2010-02-23',\n",
       "               '2010-02-24', '2010-02-25', '2010-02-26', '2010-02-27',\n",
       "               '2010-02-28', '2010-03-01',\n",
       "               ...\n",
       "               '2011-02-24', '2011-02-25', '2011-02-26', '2011-02-27',\n",
       "               '2011-02-28', '2011-03-01', '2011-03-02', '2011-03-03',\n",
       "               '2011-03-04', '2011-03-05'],\n",
       "              dtype='datetime64[ns]', length=379, freq='D')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make range of dates:\n",
    "pd.date_range('2010-02-20', '2011-03-05')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pandas-join'></a> [**Pandas - Merge, Join, Concatenate**](https://pandas.pydata.org/pandas-docs/stable/merging.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Difference between '```append```, ```concat```, ```merge```, and ```join```**\n",
    "\n",
    "**```append```**\n",
    "* Solely for appending rows to a dataframe, but it is typically slow and seldomly used in favor of concat.\n",
    "* Exists as a dataframe method (i.e. is called via df.append )\n",
    "\n",
    "**```concat```**\n",
    "* For stacking dataframes vertically or horizontally.\n",
    "* Exists in the pandas namespace (i.e. is called via pd.concat)\n",
    "\n",
    "**```merge```**\n",
    "* For performing relational database style stitching\n",
    "\n",
    "**```join```**\n",
    "* A shortcut for merging on indices as opposed to merge which allows you to join along arbitrary columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" class=\"colwidths-given docutils\">\n",
    "<colgroup>\n",
    "<col width=\"20%\">\n",
    "<col width=\"20%\">\n",
    "<col width=\"60%\">\n",
    "</colgroup>\n",
    "<thead valign=\"bottom\">\n",
    "<tr class=\"row-odd\"><th class=\"head\">Merge method</th>\n",
    "<th class=\"head\">SQL Join Name</th>\n",
    "<th class=\"head\">Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody valign=\"top\">\n",
    "<tr class=\"row-even\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">left</span></code></td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">LEFT</span> <span class=\"pre\">OUTER</span> <span class=\"pre\">JOIN</span></code></td>\n",
    "<td>Use keys from left frame only</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">right</span></code></td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">RIGHT</span> <span class=\"pre\">OUTER</span> <span class=\"pre\">JOIN</span></code></td>\n",
    "<td>Use keys from right frame only</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">outer</span></code></td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">FULL</span> <span class=\"pre\">OUTER</span> <span class=\"pre\">JOIN</span></code></td>\n",
    "<td>Use union of keys from both frames</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><code class=\"docutils literal notranslate\"><span class=\"pre\">inner</span></code></td>\n",
    "<td><code class=\"docutils literal notranslate\"><span class=\"pre\">INNER</span> <span class=\"pre\">JOIN</span></code></td>\n",
    "<td>Use intersection of keys from both frames</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example dataframes and series\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                   index=[0, 1, 2, 3])\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                    'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                    'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                    'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                   index=[4, 5, 6, 7])\n",
    " \n",
    "\n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                    'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                    'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "                    'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "                   index=[8, 9, 10, 11])\n",
    "s1 = pd.Series(['X0', 'X1', 'X2', 'X3'], name='X')\n",
    "\n",
    "s2 = pd.Series(['X0', 'X1', 'X2', 'X3'],\n",
    "               index=['A', 'B', 'C', 'D'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Difference between '```append```, ```concat```, ```merge```, and ```join```**\n",
    "\n",
    "**```append```**\n",
    "* Solely for appending rows to a dataframe, but it is typically slow and seldomly used in favor of concat.\n",
    "* Exists as a dataframe method (i.e. is called via df.append )\n",
    "\n",
    "**```concat```**\n",
    "* For stacking dataframes vertically or horizontally.\n",
    "* Exists in the pandas namespace (i.e. is called via pd.concat)\n",
    "\n",
    "**```merge```**\n",
    "* For performing relational database style stitching\n",
    "\n",
    "**```join```**\n",
    "* A shortcut for merging on indices as opposed to merge which allows you to join along arbitrary columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3\n",
      "\n",
      "A    X0\n",
      "B    X1\n",
      "C    X2\n",
      "D    X3\n",
      "dtype: object\n",
      "\n",
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3\n",
      "4  X0  X1  X2  X3 \n"
     ]
    }
   ],
   "source": [
    "# Note that Series objects are more accurately thought of as row objects rather\n",
    "# than column objects as they are typically displayed\n",
    "\n",
    "result = df1.append(s2, ignore_index=True)\n",
    "print('{}\\n\\n{}\\n\\n{} '.format(df1, s2, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "0    A0   B0   C0   D0\n",
      "1    A1   B1   C1   D1\n",
      "2    A2   B2   C2   D2\n",
      "3    A3   B3   C3   D3\n",
      "4    A4   B4   C4   D4\n",
      "5    A5   B5   C5   D5\n",
      "6    A6   B6   C6   D6\n",
      "7    A7   B7   C7   D7\n",
      "8    A8   B8   C8   D8\n",
      "9    A9   B9   C9   D9\n",
      "10  A10  B10  C10  D10\n",
      "11  A11  B11  C11  D11\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes\n",
    "#\n",
    "# - Argument must be a list of DataFrames or Series, or a dict\n",
    "# - In this example all dataframes have the same columns and non-overlapping\n",
    "################################################################################\n",
    "result = pd.concat([df1, df2, df3])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        A    B    C    D\n",
      "x 0    A0   B0   C0   D0\n",
      "  1    A1   B1   C1   D1\n",
      "  2    A2   B2   C2   D2\n",
      "  3    A3   B3   C3   D3\n",
      "y 4    A4   B4   C4   D4\n",
      "  5    A5   B5   C5   D5\n",
      "  6    A6   B6   C6   D6\n",
      "  7    A7   B7   C7   D7\n",
      "z 8    A8   B8   C8   D8\n",
      "  9    A9   B9   C9   D9\n",
      "  10  A10  B10  C10  D10\n",
      "  11  A11  B11  C11  D11\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes\n",
    "#\n",
    "# - Can attach a distinguishing label for each constituent dataframe now we \n",
    "#     will have a multiindex\n",
    "# - Concat makes a full copy of the data\n",
    "################################################################################\n",
    "result = pd.concat([df1, df2, df3], keys=['x', 'y', 'z'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A   B    C   D    F\n",
      "0   A0  B0   C0  D0  NaN\n",
      "1   A1  B1   C1  D1  NaN\n",
      "2   A2  B2   C2  D2  NaN\n",
      "3   A3  B3   C3  D3  NaN\n",
      "2  NaN  B2  NaN  D2   F2\n",
      "3  NaN  B3  NaN  D3   F3\n",
      "6  NaN  B6  NaN  D6   F6\n",
      "7  NaN  B7  NaN  D7   F7\n",
      "\n",
      "\n",
      "     A    B    C    D    B    D    F\n",
      "0   A0   B0   C0   D0  NaN  NaN  NaN\n",
      "1   A1   B1   C1   D1  NaN  NaN  NaN\n",
      "2   A2   B2   C2   D2   B2   D2   F2\n",
      "3   A3   B3   C3   D3   B3   D3   F3\n",
      "6  NaN  NaN  NaN  NaN   B6   D6   F6\n",
      "7  NaN  NaN  NaN  NaN   B7   D7   F7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casey/coding_interview/interview_venv/lib/python3.5/site-packages/ipykernel_launcher.py:13: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes\n",
    "#\n",
    "# - The default merge method is 'outer' meaning that it will use the union of \n",
    "#     all keys in both dataframes\n",
    "# - Note that with an outer join it fills all missing fields with nans\n",
    "################################################################################\n",
    "df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "                    'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "                    'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "                   index=[2, 3, 6, 7])\n",
    "# Concatenate along rows (i.e. vertical stacking)\n",
    "result = pd.concat([df1, df4], axis=0)\n",
    "print(result)\n",
    "print('\\n')\n",
    "# Concatenate along columns (i.e. horizontal stacking)\n",
    "result = pd.concat([df1, df4], axis=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    B   D\n",
      "0  B0  D0\n",
      "1  B1  D1\n",
      "2  B2  D2\n",
      "3  B3  D3\n",
      "2  B2  D2\n",
      "3  B3  D3\n",
      "6  B6  D6\n",
      "7  B7  D7\n",
      "\n",
      "\n",
      "    A   B   C   D   B   D   F\n",
      "2  A2  B2  C2  D2  B2  D2  F2\n",
      "3  A3  B3  C3  D3  B3  D3  F3\n",
      "\n",
      "\n",
      "    A   B   C   D    B    D    F\n",
      "0  A0  B0  C0  D0  NaN  NaN  NaN\n",
      "1  A1  B1  C1  D1  NaN  NaN  NaN\n",
      "2  A2  B2  C2  D2   B2   D2   F2\n",
      "3  A3  B3  C3  D3   B3   D3   F3\n",
      "\n",
      "\n",
      "    B   D   F    A    B    C    D\n",
      "2  B2  D2  F2   A2   B2   C2   D2\n",
      "3  B3  D3  F3   A3   B3   C3   D3\n",
      "6  B6  D6  F6  NaN  NaN  NaN  NaN\n",
      "7  B7  D7  F7  NaN  NaN  NaN  NaN\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes - Inner Joins\n",
    "#\n",
    "# - A join of inner only returns the columns and rows that can be filled in\n",
    "#     completely, i.e. the intersection\n",
    "################################################################################\n",
    "df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "                    'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "                    'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "                   index=[2, 3, 6, 7])\n",
    "# Concatenate along rows (i.e. vertical stacking)\n",
    "# Drops columns A, C since the are not present in df4, it drops F not in df1\n",
    "result = pd.concat([df1, df4], join='inner', axis=0)\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Concatenate along columns (i.e. horizontal stacking)\n",
    "# Drops rows 0, 1, not in df4 and 6, 7 not in df1\n",
    "result = pd.concat([df1, df4], join='inner', axis=1)\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Concatenate along columns (i.e. horizontal stacking)\n",
    "# We can perform something between an inner and an outer join by specifying we\n",
    "# want to use only the keys from one but not the other (as opposed to an outer\n",
    "# join which uses the union)\n",
    "result = pd.concat([df1, df4], axis=1, join_axes=[df1.index])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "result = pd.concat([df4, df1], axis=1, join_axes=[df4.index])\n",
    "print(result)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A   B    C   D    F\n",
      "0   A0  B0   C0  D0  NaN\n",
      "1   A1  B1   C1  D1  NaN\n",
      "2   A2  B2   C2  D2  NaN\n",
      "3   A3  B3   C3  D3  NaN\n",
      "4  NaN  B2  NaN  D2   F2\n",
      "5  NaN  B3  NaN  D3   F3\n",
      "6  NaN  B6  NaN  D6   F6\n",
      "7  NaN  B7  NaN  D7   F7\n",
      "\n",
      "\n",
      "     0    1    2    3    4    5    6\n",
      "0   A0   B0   C0   D0  NaN  NaN  NaN\n",
      "1   A1   B1   C1   D1  NaN  NaN  NaN\n",
      "2   A2   B2   C2   D2   B2   D2   F2\n",
      "3   A3   B3   C3   D3   B3   D3   F3\n",
      "6  NaN  NaN  NaN  NaN   B6   D6   F6\n",
      "7  NaN  NaN  NaN  NaN   B7   D7   F7\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casey/coding_interview/interview_venv/lib/python3.5/site-packages/ipykernel_launcher.py:12: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes - resetting index\n",
    "#\n",
    "# - Can reset index and make sequential\n",
    "################################################################################\n",
    "df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "                    'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "                    'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "                   index=[2, 3, 6, 7])\n",
    "# Concatenate along rows (i.e. vertical stacking)\n",
    "# Resets row numbers\n",
    "result = pd.concat([df1, df4], axis=0, ignore_index=True)\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Concatenate along columns (i.e. horizontal stacking)\n",
    "# Resets column names\n",
    "result = pd.concat([df1, df4], axis=1, ignore_index=True)\n",
    "print(result)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,\n",
    "         left_index=False, right_index=False, sort=True,\n",
    "         suffixes=('_x', '_y'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B key   C   D\n",
      "0  A0  B0  K0  C0  D0\n",
      "1  A1  B1  K1  C1  D1\n",
      "2  A2  B2  K2  C2  D2\n",
      "3  A3  B3  K3  C3  D3\n",
      "\n",
      "\n",
      "    C   D key   A   B\n",
      "0  C0  D0  K0  A0  B0\n",
      "1  C1  D1  K1  A1  B1\n",
      "2  C2  D2  K2  A2  B2\n",
      "3  C3  D3  K3  A3  B3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes - Merging on common column one-to-one\n",
    "#\n",
    "# - Think about merging as stitching or mappings\n",
    "# - The default join is INNER\n",
    "################################################################################\n",
    "table1 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                       'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                       'B': ['B0', 'B1', 'B2', 'B3']})\n",
    " \n",
    "\n",
    "table2 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                       'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                       'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "# Merging on common column  'key'\n",
    "result = pd.merge(left=table1, right=table2, on='key')\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Merging on common column  'key' in reverse order\n",
    "# Since the keys are one-to-one these are the same (though the columns are permuted)\n",
    "result = pd.merge(left=table2, right=table1, on='key')\n",
    "print(result)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B key1 key2\n",
      "0  A0  B0   K0   K0\n",
      "1  A1  B1   K0   K1\n",
      "2  A2  B2   K1   K0\n",
      "3  A3  B3   K2   K1\n",
      "\n",
      "\n",
      "    C   D key1 key2\n",
      "0  C0  D0   K0   K0\n",
      "1  C1  D1   K1   K0\n",
      "2  C2  D2   K1   K0\n",
      "3  C3  D3   K2   K0\n",
      "\n",
      "\n",
      "    A   B key1 key2_x   C   D key2_y\n",
      "0  A0  B0   K0     K0  C0  D0     K0\n",
      "1  A1  B1   K0     K1  C0  D0     K0\n",
      "2  A2  B2   K1     K0  C1  D1     K0\n",
      "3  A2  B2   K1     K0  C2  D2     K0\n",
      "4  A3  B3   K2     K1  C3  D3     K0\n",
      "\n",
      "\n",
      "    C   D key1 key2_x   A   B key2_y\n",
      "0  C0  D0   K0     K0  A0  B0     K0\n",
      "1  C0  D0   K0     K0  A1  B1     K1\n",
      "2  C1  D1   K1     K0  A2  B2     K0\n",
      "3  C2  D2   K1     K0  A2  B2     K0\n",
      "4  C3  D3   K2     K0  A3  B3     K1\n",
      "\n",
      "\n",
      "    A   B key1 key2   C   D\n",
      "0  A0  B0   K0   K0  C0  D0\n",
      "1  A2  B2   K1   K0  C1  D1\n",
      "2  A2  B2   K1   K0  C2  D2\n",
      "\n",
      "\n",
      "    C   D key1 key2   A   B\n",
      "0  C0  D0   K0   K0  A0  B0\n",
      "1  C1  D1   K1   K0  A2  B2\n",
      "2  C2  D2   K1   K0  A2  B2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes - Merging on multiple columns\n",
    "#\n",
    "# - The domain of the mapping is the left key, return all entries in right table\n",
    "#     that match that key\n",
    "# - If there are common columns in both tables which are not joined on then they\n",
    "#     will be added but with suffixes '_x' for the left and '_y' for the right\n",
    "################################################################################\n",
    "\n",
    "table1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']}) \n",
    "\n",
    "table2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                      'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                      'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "print(table1)\n",
    "print('\\n')\n",
    "print(table2)\n",
    "print('\\n')\n",
    "\n",
    "# Join on single key\n",
    "result = pd.merge(left=table1, right=table2, on=['key1'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Note that the join is commutative since we are performing an inner join\n",
    "# The only difference is the suffixes added on the non-joined common column\n",
    "# key2\n",
    "result = pd.merge(left=table2, right=table1, on=['key1'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Join on multiple keys means that both keys have to match both keys in\n",
    "# the target table. So, since table2 has no entry with (key1, key2) = (K0, K1)\n",
    "# this is not entered into the resulting (since this is an inner join)\n",
    "result = pd.merge(left=table1, right=table2, on=['key1', 'key2'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "result = pd.merge(left=table2, right=table1, on=['key1', 'key2'])\n",
    "print(result)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B key1 key2    C    D\n",
      "0   A0   B0   K0   K0   C0   D0\n",
      "1   A1   B1   K0   K1  NaN  NaN\n",
      "2   A2   B2   K1   K0   C1   D1\n",
      "3   A2   B2   K1   K0   C2   D2\n",
      "4   A3   B3   K2   K1  NaN  NaN\n",
      "5  NaN  NaN   K2   K0   C3   D3\n",
      "\n",
      "\n",
      "     C    D key1 key2    A    B\n",
      "0   C0   D0   K0   K0   A0   B0\n",
      "1   C1   D1   K1   K0   A2   B2\n",
      "2   C2   D2   K1   K0   A2   B2\n",
      "3   C3   D3   K2   K0  NaN  NaN\n",
      "4  NaN  NaN   K0   K1   A1   B1\n",
      "5  NaN  NaN   K2   K1   A3   B3\n",
      "\n",
      "\n",
      "    A   B key1 key2_x   C   D key2_y\n",
      "0  A0  B0   K0     K0  C0  D0     K0\n",
      "1  A1  B1   K0     K1  C0  D0     K0\n",
      "2  A2  B2   K1     K0  C1  D1     K0\n",
      "3  A2  B2   K1     K0  C2  D2     K0\n",
      "4  A3  B3   K2     K1  C3  D3     K0\n",
      "\n",
      "\n",
      "    C   D key1 key2_x   A   B key2_y\n",
      "0  C0  D0   K0     K0  A0  B0     K0\n",
      "1  C0  D0   K0     K0  A1  B1     K1\n",
      "2  C1  D1   K1     K0  A2  B2     K0\n",
      "3  C2  D2   K1     K0  A2  B2     K0\n",
      "4  C3  D3   K2     K0  A3  B3     K1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes - Full Outer Join\n",
    "#\n",
    "# - builds table with union of all keys from both left and right tables\n",
    "################################################################################\n",
    "\n",
    "table1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']}) \n",
    "\n",
    "table2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                      'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                      'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "# Table will include all pairs from both left and right tables:\n",
    "#  From left:  (K0, K0), (K0, K1), (K1, K0), (K2, K1)\n",
    "#  From right: (K0, K0), (K1, K0), (K1, K0), (K2, K0)\n",
    "# All elements which do not have a counterpart will be filled with NaNs\n",
    "result = pd.merge(left=table1, right=table2, how='outer', on=['key1', 'key2'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Note that up to column ordering the two tables are the same\n",
    "result = pd.merge(left=table2, right=table1, how='outer', on=['key1', 'key2'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "result = pd.merge(left=table1, right=table2, how='outer', on=['key1'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Note that up to column ordering the two tables are the same\n",
    "result = pd.merge(left=table2, right=table1, how='outer', on=['key1'])\n",
    "print(result)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B key1 key2    C    D\n",
      "0  A0  B0   K0   K0   C0   D0\n",
      "1  A1  B1   K0   K1  NaN  NaN\n",
      "2  A2  B2   K1   K0   C1   D1\n",
      "3  A2  B2   K1   K0   C2   D2\n",
      "4  A3  B3   K2   K1  NaN  NaN\n",
      "\n",
      "\n",
      "    C   D key1 key2    A    B\n",
      "0  C0  D0   K0   K0   A0   B0\n",
      "1  C1  D1   K1   K0   A2   B2\n",
      "2  C2  D2   K1   K0   A2   B2\n",
      "3  C3  D3   K2   K0  NaN  NaN\n",
      "\n",
      "\n",
      "     A    B key1 key2   C   D\n",
      "0   A0   B0   K0   K0  C0  D0\n",
      "1   A2   B2   K1   K0  C1  D1\n",
      "2   A2   B2   K1   K0  C2  D2\n",
      "3  NaN  NaN   K2   K0  C3  D3\n",
      "\n",
      "\n",
      "     C    D key1 key2   A   B\n",
      "0   C0   D0   K0   K0  A0  B0\n",
      "1   C1   D1   K1   K0  A2  B2\n",
      "2   C2   D2   K1   K0  A2  B2\n",
      "3  NaN  NaN   K0   K1  A1  B1\n",
      "4  NaN  NaN   K2   K1  A3  B3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes - Left/Right Outer Join\n",
    "#\n",
    "# - Builds table using all of the keys in either the left or right table\n",
    "################################################################################\n",
    "\n",
    "table1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']}) \n",
    "\n",
    "table2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                      'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                      'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "# This will have all of the keys from the left table. If there is no corresponding\n",
    "# element in the right table, they will be filled with NaNs. Also, a left key can\n",
    "# be duplicated if there are multiple entries in the right table with the same key\n",
    "result = pd.merge(left=table1, right=table2, how='left', on=['key1', 'key2'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Note that this is NON-COMMUTATIVE\n",
    "result = pd.merge(left=table2, right=table1, how='left', on=['key1', 'key2'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# This will have all of the keys in the right table\n",
    "result = pd.merge(left=table1, right=table2, how='right', on=['key1', 'key2'])\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Note however that left<->right and table1<->table2 is commutative\n",
    "result = pd.merge(left=table2, right=table1, how='right', on=['key1', 'key2'])\n",
    "print(result)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join is really just a shorthand for merging on the indexes of the two tables by default. However, you can include a column argument to join to match a column in the left to an index on the right.\n",
    "i.e. the two are the same\n",
    "\n",
    "```python\n",
    "left.join(right, on=key_or_keys)\n",
    "pd.merge(left=left, right=right, left_on=key_or_keys, right_index=True, how='left')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B key    C    D\n",
      "0  A0  B0  K0  NaN  NaN\n",
      "1  A1  B1  K1  NaN  NaN\n",
      "2  A2  B2  K0  NaN  NaN\n",
      "3  A3  B3  K1  NaN  NaN\n",
      "\n",
      "\n",
      "    A   B key   C   D\n",
      "0  A0  B0  K0  C0  D0\n",
      "1  A1  B1  K1  C1  D1\n",
      "2  A2  B2  K0  C0  D0\n",
      "3  A3  B3  K1  C1  D1\n",
      "\n",
      "\n",
      "  A_l B_l key_l    A    B  key\n",
      "0  A0  B0    K0   E0   D0   K0\n",
      "1  A1  B1    K1   E1   D1   K1\n",
      "2  A2  B2    K0   E2   D2   K1\n",
      "3  A3  B3    K1  NaN  NaN  NaN\n",
      "\n",
      "\n",
      "    A   B key_l    F    G key_r\n",
      "0  A0  B0    K0   F0   G0    K0\n",
      "1  A1  B1    K1   F1   G1    K1\n",
      "2  A2  B2    K0   F2   G2    K1\n",
      "3  A3  B3    K1  NaN  NaN   NaN\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Notes - .join()\n",
    "#\n",
    "# - Shorthand designed for joining on indexes\n",
    "# - Default is a left outer join\n",
    "################################################################################\n",
    "\n",
    "table1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                       'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                       'key': ['K0', 'K1', 'K0', 'K1']})\n",
    "\n",
    "table2 = pd.DataFrame({'C': ['C0', 'C1'],\n",
    "                       'D': ['D0', 'D1']},\n",
    "                       index=['K0', 'K1'])\n",
    "\n",
    "table3 = pd.DataFrame({'A': ['E0', 'E1', 'E2'],\n",
    "                       'B': ['D0', 'D1', 'D2'],\n",
    "                       'key': ['K0', 'K1', 'K1',]})\n",
    "\n",
    "table4 = pd.DataFrame({'F': ['F0', 'F1', 'F2'],\n",
    "                       'G': ['G0', 'G1', 'G2'],\n",
    "                       'key': ['K0', 'K1', 'K1',]})\n",
    "\n",
    "# Note that since table 2's index is not a set of integers, but a set of strings\n",
    "# So, when it attempts to join, it will try to join on their indexes, but it\n",
    "# can't match any so all of right columns are filled with NaNs\n",
    "result = table1.join(table2)\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Now we tell it to instead join on table1's column='key' which finds matches in\n",
    "# table2's index\n",
    "result = table1.join(table2, on='key')\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Here will be able to match their indexes since they are both just row numbers.\n",
    "# However, the tables have columns with the same name, so we need to specify what\n",
    "# suffixes we want to add to the left or right column names to distinguish them\n",
    "result = table1.join(table3, lsuffix='_l')\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "result = table1.join(table4, lsuffix='_l', rsuffix='_r')\n",
    "print(result)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Difference between '```append```, ```concat```, ```merge```, and ```join```**\n",
    "\n",
    "**```append```**\n",
    "* Solely for appending rows to a dataframe, but it is typically slow and seldomly used in favor of concat.\n",
    "* Exists as a dataframe method (i.e. is called via df.append )\n",
    "\n",
    "**```concat```**\n",
    "* For stacking dataframes vertically or horizontally.\n",
    "* Exists in the pandas namespace (i.e. is called via pd.concat)\n",
    "\n",
    "**```merge```**\n",
    "* For performing relational database style stitching\n",
    "\n",
    "**```join```**\n",
    "* A shortcut for merging on indices as opposed to merge which allows you to join along arbitrary columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Functions used to generate mock data simulating the tables given above.\n",
    "\n",
    "n_students = 1000\n",
    "n_days = 10\n",
    "start_date = '2017-09-01'\n",
    "end_date = '2018-06-15'\n",
    "\n",
    "################################################################################\n",
    "# Attendance Table                                                             #\n",
    "################################################################################\n",
    "def _make_event_dates(n_students, start_date, end_date):\n",
    "    dr = pd.date_range(start_date, end_date)\n",
    "    dates = []\n",
    "    for day in dr:\n",
    "        dates.extend([day] * n_students)\n",
    "    return dates\n",
    "\n",
    "def _make_student_ids(n_students, n_days=None):\n",
    "    student_ids = [xx for xx in range(100, 100 + n_students)]\n",
    "    if n_days is not None:\n",
    "        student_ids = student_ids * n_days\n",
    "    return student_ids\n",
    "\n",
    "def _make_attendance(n_students, n_days):\n",
    "    return list(np.random.choice(2, n_students, p=[0.3, 0.7])) * n_days\n",
    "\n",
    "def build_attendance_events(n_students, start_date, end_date):\n",
    "    columns = ['date', 'student_id', 'attendance']\n",
    "    n_days = len(pd.date_range(start_date, end_date))\n",
    "    \n",
    "    dates       = _make_event_dates(n_students, start_date, end_date)\n",
    "    student_ids = _make_student_ids(n_students, n_days)\n",
    "    attendance  = _make_attendance(n_students, n_days)\n",
    "    data = [xx for xx in zip(dates, student_ids, attendance)]\n",
    "    \n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "    return df\n",
    "\n",
    "################################################################################\n",
    "# District All Students Table                                                  #\n",
    "################################################################################\n",
    "def _make_school_ids(n_students):\n",
    "    schools = ['South River High School',\n",
    "               'New Brunswick High School',\n",
    "               'East Brunswick High School',\n",
    "               'Edison High School']\n",
    "    return list(np.random.choice(schools, n_students))\n",
    "\n",
    "def _make_grade_levels(n_students):\n",
    "    grades = ['Freshman', 'Sophomore', 'Junior', 'Senior']\n",
    "    return list(np.random.choice(grades, n_students))\n",
    "    \n",
    "def _make_DOBs(grade_levels):\n",
    "    birth_years = {\n",
    "        'Freshman': 2005,\n",
    "        'Sophomore': 2004,\n",
    "        'Junior': 2003,\n",
    "        'Senior': 2002\n",
    "    }\n",
    "    years = [birth_years[xx] for xx in grade_levels]\n",
    "    months = list(np.random.choice(np.arange(1,13), len(grade_levels)))\n",
    "    days = list(np.random.choice(np.arange(1,29), len(grade_levels)))\n",
    "    DOBs = pd.to_datetime(['{}-{}-{}'.format(*dd) for dd in zip(months, days, years)])\n",
    "    return DOBs\n",
    "\n",
    "def _make_hometowns(school_ids):\n",
    "    hometowns = [school.split('High School')[0].strip() for school in school_ids]\n",
    "    return hometowns\n",
    "    \n",
    "\n",
    "def build_all_students(n_students):\n",
    "    student_ids  = _make_student_ids(n_students)\n",
    "    school_ids   = _make_school_ids(n_students)\n",
    "    grade_levels = _make_grade_levels(n_students)\n",
    "    DOBs         = _make_DOBs(grade_levels)\n",
    "    hometowns    = _make_hometowns(school_ids)\n",
    "    \n",
    "    columns = ['student_id', 'school_id', 'grade_level', 'date_of_birth', 'hometown']\n",
    "    data = [xx for xx in zip(student_ids, school_ids, grade_levels, DOBs, hometowns)]\n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "    return df\n",
    "    \n",
    "\n",
    "attendance_events = build_attendance_events(n_students, start_date, end_date)\n",
    "all_students = build_all_students(n_students=n_students)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pandas-groupby'></a> [**Pandas - Group By: split-apply-combine**](https://pandas.pydata.org/pandas-docs/stable/groupby.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview_prep",
   "language": "python",
   "name": "interview_prep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
